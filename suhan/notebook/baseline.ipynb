{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6n-Ps2nkVsBb"
   },
   "source": [
    "# **💁🏻🗨️💁🏻‍♂️대화 요약 Baseline code**\n",
    "> **Dialogue Summarization** 경진대회에 오신 여러분 환영합니다! 🎉    \n",
    "> 본 대회에서는 최소 2명에서 최대 7명이 등장하여 나누는 대화를 요약하는 BART 기반 모델의 baseline code를 제공합니다.     \n",
    "> 주어진 데이터를 활용하여 일상 대화에 대한 요약을 효과적으로 생성하는 모델을 만들어봅시다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNq_LylZa1ug"
   },
   "source": [
    "## ⚙️ 데이터 및 환경설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjCiuI_V4glr"
   },
   "source": [
    "### 1) 필요한 라이브러리 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYqDF_-r2ToB"
   },
   "source": [
    "- 필요한 라이브러리를 설치한 후 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from rouge import Rouge # 모델의 성능을 평가하기 위한 라이브러리입니다.\n",
    "# from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration, T5Config\n",
    "import random\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, BartConfig\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "import wandb # 모델 학습 과정을 손쉽게 Tracking하고, 시각화할 수 있는 라이브러리입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Qq46k6_CNQn"
   },
   "source": [
    "### 2) Config file 만들기 (선택)\n",
    "- 모델 생성에 필요한 다양한 매개변수 정보를 저장할 수 있습니다.  \n",
    "  따라서, 코드 상에서 모델의 매개변수를 설정할 수도 있지만 독립적인 매개변수 정보 파일을 생성하여 관리할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197,
     "referenced_widgets": [
      "e920dbc173c045d1a32143349f1dff8e",
      "58c794fb7ce543a39fdf66d757f6eeab",
      "8a6464a355f7464c989033965d418a8a",
      "3645438ace1f4596a8dbc157b48c1521",
      "58001a60eacc44d5b38a68648adccde4",
      "6f5fde5b0ac840a18bd5cc380e564ff6",
      "45187decb58b4ad39ad532259c6277e5",
      "2307c6dcbe0141acb5e61baae19cade7",
      "4747b668e2fa4ab58a449446f80030f5",
      "14f6c91d6c634379b498586c51e606e0",
      "08d05bc20a96432badd459e1ffaf868e",
      "5dfcf310ca9e4e2794076098a5d69cea",
      "3c284a826f6843f6aa47eacad478ac30",
      "6caedd60c6b747469c82930be1f95d6d",
      "64f2218f899d446393cfea44f206f0a6",
      "d068f541df3f438dbd5138863e64b2f2",
      "affff1d8a89e4c14955d1b2aa39ff1ab",
      "13651c09564a4337b8274c1cb436faa5",
      "3bcd6b6b956347b29e1efa20a1d00542",
      "2fd3d7bbcd6948d8904d33001f95ea03",
      "d22fbc2c5dbf422399e496c9b500025a",
      "775d8bbeceac4e2da4f21ab6235c89ed",
      "de1a3f7701c243839fe03b930a9b9e30",
      "ebc22683058a4f229c5588e52fc93536",
      "52095cc7087243ac916055e569fd22f3",
      "a15af9e8158f4903b9189f3d322a5ef3",
      "21d2e54b5a0a4f79973a512105da43eb",
      "083ea69907bb48d4a8fff919bac51aad",
      "2a190bda0b72407e9a953cd2104dd3b2",
      "c18f0e3bc35e44d9915c3f84cd282a26",
      "3a04e871b74b45d7bf02fd33bb103577",
      "ac00d6c2cf974b33a628acb3f1471316",
      "285007b45236478ca147c6df752c8da4"
     ]
    },
    "id": "gZOE9TInCQHJ",
    "outputId": "8ce58487-6199-408c-cb37-49af1e218bc2"
   },
   "outputs": [],
   "source": [
    "# config 설정에 tokenizer 모듈이 사용되므로 미리 tokenizer를 정의해줍니다.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"digit82/kobart-summarization\") #v1\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"noahkim/KoT5_news_summarization\")\n",
    "# lcw99/t5-large-korean-text-summary\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"digit82/kobart-summarization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "5vsACJI7CVb8"
   },
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"/root/dialogue/data\", # 모델 생성에 필요한 데이터 경로를 사용자 환경에 맞게 지정합니다.\n",
    "        \"model_name\": 'EbanLee/kobart-summary-v3', # 불러올 모델의 이름을 사용자 환경에 맞게 지정할 수 있습니다.\n",
    "        \"output_dir\": \"./\" # 모델의 최종 출력 값을 저장할 경로를 설정합니다.\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 500,\n",
    "        \"decoder_max_len\": 100,\n",
    "        \"bos_token\": \"<s>\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        \"sep_token\": \"<sep>\",\n",
    "        # \"mask_token\": f\"{tokenizer.mask_token}\",\n",
    "        # 특정 단어들이 분해되어 tokenization이 수행되지 않도록 special_tokens을 지정해줍니다.\n",
    "        \"special_tokens\": [\"#PhoneNumber#\", \"#Address#\", \"#DateOfBirth#\", \n",
    "    \"#PassportNumber#\", \"#SSN#\", \"#CardNumber#\", \n",
    "    \"#CarNumber#\", \"#Email#\",\"#Person1#\", \"#Person2#\", \"#Person3#\"]\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": 30,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"per_device_train_batch_size\": 50,\n",
    "        \"per_device_eval_batch_size\": 32,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr_scheduler_type\": 'cosine',\n",
    "        \"optim\": 'adamw_torch',\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"evaluation_strategy\": 'epoch',\n",
    "        \"save_strategy\": 'epoch',\n",
    "        \"save_total_limit\": 5,\n",
    "        \"fp16\": True,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"seed\": 42,\n",
    "        \"logging_dir\": \"./logs\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 200,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"early_stopping_patience\": 4,\n",
    "        \"early_stopping_threshold\": 0.001,\n",
    "        \"report_to\": \"wandb\" # (선택) wandb를 사용할 때 설정합니다.\n",
    "    },\n",
    "    # (선택) wandb 홈페이지에 가입하여 얻은 정보를 기반으로 작성합니다.\n",
    "    \"wandb\": {\n",
    "        \"entity\": \"wandb_repo\",\n",
    "        \"project\": \"dialogue\",\n",
    "        \"name\": \"suhan_up\"\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_path\": \"model ckt path\", # 사전 학습이 진행된 모델의 checkpoint를 저장할 경로를 설정합니다.\n",
    "        \"result_path\": \"./prediction/\",\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 100,\n",
    "        \"num_beams\": 4,\n",
    "        \"batch_size\" : 32,\n",
    "        # 정확한 모델 평가를 위해 제거할 불필요한 생성 토큰들을 정의합니다.\n",
    "        \"remove_tokens\": ['<usr>', '<s>', f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\", \"<sep>\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cm7ob25lHBkR"
   },
   "source": [
    "- 참고✅    \n",
    ": wandb 라이브러리를 사용하기 위해선 entity, project, name를 지정해주어야 합니다. wandb 홈페이지에 가입한 후 얻은 정보를 입력하여 작동할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "REJybO5UCabF"
   },
   "outputs": [],
   "source": [
    "# 모델의 구성 정보를 YAML 파일로 저장합니다.\n",
    "config_path = \"./config.yaml\"\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObEASD6Wj6pl"
   },
   "source": [
    "### 3) Configuration 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUBm_6RqlYpV",
    "outputId": "4b1c8c44-c6a9-40f1-adbd-72d48f0c983b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': {'data_path': '/root/dialogue/data',\n",
      "             'model_name': 'EbanLee/kobart-summary-v3',\n",
      "             'output_dir': './'},\n",
      " 'inference': {'batch_size': 32,\n",
      "               'ckt_path': 'model ckt path',\n",
      "               'early_stopping': True,\n",
      "               'generate_max_length': 100,\n",
      "               'no_repeat_ngram_size': 2,\n",
      "               'num_beams': 4,\n",
      "               'remove_tokens': ['<usr>', '<s>', '</s>', '<pad>', '<sep>'],\n",
      "               'result_path': './prediction/'},\n",
      " 'tokenizer': {'bos_token': '<s>',\n",
      "               'decoder_max_len': 100,\n",
      "               'encoder_max_len': 500,\n",
      "               'eos_token': '</s>',\n",
      "               'sep_token': '<sep>',\n",
      "               'special_tokens': ['#PhoneNumber#',\n",
      "                                  '#Address#',\n",
      "                                  '#DateOfBirth#',\n",
      "                                  '#PassportNumber#',\n",
      "                                  '#SSN#',\n",
      "                                  '#CardNumber#',\n",
      "                                  '#CarNumber#',\n",
      "                                  '#Email#',\n",
      "                                  '#Person1#',\n",
      "                                  '#Person2#',\n",
      "                                  '#Person3#']},\n",
      " 'training': {'do_eval': True,\n",
      "              'do_train': True,\n",
      "              'early_stopping_patience': 4,\n",
      "              'early_stopping_threshold': 0.001,\n",
      "              'evaluation_strategy': 'epoch',\n",
      "              'fp16': True,\n",
      "              'generation_max_length': 200,\n",
      "              'gradient_accumulation_steps': 1,\n",
      "              'learning_rate': 1e-05,\n",
      "              'load_best_model_at_end': True,\n",
      "              'logging_dir': './logs',\n",
      "              'logging_strategy': 'epoch',\n",
      "              'lr_scheduler_type': 'cosine',\n",
      "              'num_train_epochs': 30,\n",
      "              'optim': 'adamw_torch',\n",
      "              'overwrite_output_dir': True,\n",
      "              'per_device_eval_batch_size': 32,\n",
      "              'per_device_train_batch_size': 50,\n",
      "              'predict_with_generate': True,\n",
      "              'report_to': 'wandb',\n",
      "              'save_strategy': 'epoch',\n",
      "              'save_total_limit': 5,\n",
      "              'seed': 42,\n",
      "              'warmup_ratio': 0.1,\n",
      "              'weight_decay': 0.01},\n",
      " 'wandb': {'entity': 'wandb_repo', 'name': 'suhan_up', 'project': 'dialogue'}}\n"
     ]
    }
   ],
   "source": [
    "# 저장된 config 파일을 불러옵니다.\n",
    "config_path = \"./config.yaml\"\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "\n",
    "# 불러온 config 파일의 전체 내용을 확인합니다.\n",
    "pprint(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRSbKEVslhwO",
    "outputId": "40ba5c67-574e-4f86-cbac-13e9f01c588a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_path': '../data/translate',\n",
       " 'model_name': 'facebook/bart-large',\n",
       " 'output_dir': './'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실험에 쓰일 데이터의 경로, 사용될 모델, 모델의 최종 출력 결과를 저장할 경로에 대해 확인합니다.\n",
    "loaded_config['general']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이곳에 사용자가 저장한 데이터 dir 설정하기\n",
    "# loaded_config['general']['data_path'] = \"data_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1pvFmIOqljv1",
    "outputId": "958c9b06-90de-4872-b2fb-cf739a655b4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'decoder_max_len': 200,\n",
       " 'encoder_max_len': 900,\n",
       " 'eos_token': '</s>',\n",
       " 'sep_token': '<sep>',\n",
       " 'special_tokens': ['#PhoneNumber#',\n",
       "  '#Address#',\n",
       "  '#DateOfBirth#',\n",
       "  '#PassportNumber#',\n",
       "  '#SSN#',\n",
       "  '#CardNumber#',\n",
       "  '#CarNumber#',\n",
       "  '#Email#',\n",
       "  '#Person1#',\n",
       "  '#Person2#',\n",
       "  '#Person3#']}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리를 하기 위해 tokenization 과정에서 필요한 정보들을 확인합니다.\n",
    "loaded_config['tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEvwCIBVll-h",
    "outputId": "ca010ac3-05be-4983-d665-2a653f0ced0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'do_eval': True,\n",
       " 'do_train': True,\n",
       " 'early_stopping_patience': 3,\n",
       " 'early_stopping_threshold': 0.001,\n",
       " 'evaluation_strategy': 'epoch',\n",
       " 'fp16': True,\n",
       " 'generation_max_length': 120,\n",
       " 'gradient_accumulation_steps': 1,\n",
       " 'learning_rate': 1e-05,\n",
       " 'load_best_model_at_end': True,\n",
       " 'logging_dir': './logs',\n",
       " 'logging_strategy': 'epoch',\n",
       " 'lr_scheduler_type': 'cosine',\n",
       " 'num_train_epochs': 20,\n",
       " 'optim': 'adamw_torch',\n",
       " 'overwrite_output_dir': True,\n",
       " 'per_device_eval_batch_size': 32,\n",
       " 'per_device_train_batch_size': 50,\n",
       " 'predict_with_generate': True,\n",
       " 'report_to': 'wandb',\n",
       " 'save_strategy': 'epoch',\n",
       " 'save_total_limit': 5,\n",
       " 'seed': 42,\n",
       " 'warmup_ratio': 0.1,\n",
       " 'weight_decay': 0.01}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델이 훈련 시 적용될 매개변수를 확인합니다.\n",
    "loaded_config['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xhqHf1njlnyg",
    "outputId": "be9519c6-118b-4e4f-ea11-4bcca0ac42bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity': 'wandb_repo', 'name': 'preprocess,v3', 'project': 'dialogue'}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 과정에 대한 정보를 제공해주는 wandb 설정 내용을 확인합니다.\n",
    "loaded_config['wandb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (선택) 이곳에 사용자가 사용할 wandb config 설정\n",
    "# loaded_config['wandb']['entity'] = \"사용할 wandb repo name\"\n",
    "loaded_config['wandb']['name'] = \"bartv3\"\n",
    "loaded_config['wandb']['project'] = \"summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fm4gxPRVlppj",
    "outputId": "1342aa36-3934-4f73-c912-e7d35fe6df06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'ckt_path': 'model ckt path',\n",
       " 'early_stopping': True,\n",
       " 'generate_max_length': 100,\n",
       " 'no_repeat_ngram_size': 2,\n",
       " 'num_beams': 4,\n",
       " 'remove_tokens': ['<usr>', '<s>', '</s>', '<pad>', '<sep>'],\n",
       " 'result_path': './prediction/'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델이 최종 결과를 출력하기 위한 매개변수 정보를 확인합니다.\n",
    "loaded_config['inference']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2zt0b-8ogCL"
   },
   "source": [
    "### 4) 데이터 불러와서 확인해보기\n",
    "- 실험에서 쓰일 데이터를 load하여 데이터의 구조와 내용을 살펴보겠습니다.\n",
    "- Train, dev, test 순서대로 12457, 499, 250개 씩 데이터가 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "QFHIE2G04y-K",
    "outputId": "19312d21-f5bf-495f-c626-cc17b82024a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나...</td>\n",
       "      <td>스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니...</td>\n",
       "      <td>건강검진 받기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>#Person1#: 안녕하세요, 파커 부인, 어떻게 지내셨나요?\\n#Person2#...</td>\n",
       "      <td>파커 부인이 리키를 데리고 백신 접종을 하러 갔다. 피터스 박사는 기록을 확인한 후...</td>\n",
       "      <td>백신</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>#Person1#: 실례합니다, 열쇠 한 묶음 보셨나요?\\n#Person2#: 어떤...</td>\n",
       "      <td>#Person1#은 열쇠 한 묶음을 찾고 있고, 그것을 찾기 위해 #Person2#...</td>\n",
       "      <td>열쇠 찾기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>#Person1#: 왜 너는 여자친구가 있다는 걸 말해주지 않았어?\\n#Person...</td>\n",
       "      <td>#Person1#은 #Person2#가 여자친구가 있고 그녀와 결혼할 것이라는 사실...</td>\n",
       "      <td>여자친구가 있다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>#Person1#: 안녕, 숙녀분들! 오늘 밤 당신들은 정말 멋져 보여. 이 춤을 ...</td>\n",
       "      <td>말릭이 니키에게 춤을 요청한다. 말릭이 발을 밟는 것을 신경 쓰지 않는다면 니키는 ...</td>\n",
       "      <td>댄스</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fname                                           dialogue  \\\n",
       "0  train_0  #Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나...   \n",
       "1  train_1  #Person1#: 안녕하세요, 파커 부인, 어떻게 지내셨나요?\\n#Person2#...   \n",
       "2  train_2  #Person1#: 실례합니다, 열쇠 한 묶음 보셨나요?\\n#Person2#: 어떤...   \n",
       "3  train_3  #Person1#: 왜 너는 여자친구가 있다는 걸 말해주지 않았어?\\n#Person...   \n",
       "4  train_4  #Person1#: 안녕, 숙녀분들! 오늘 밤 당신들은 정말 멋져 보여. 이 춤을 ...   \n",
       "\n",
       "                                             summary     topic  \n",
       "0  스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니...   건강검진 받기  \n",
       "1  파커 부인이 리키를 데리고 백신 접종을 하러 갔다. 피터스 박사는 기록을 확인한 후...        백신  \n",
       "2  #Person1#은 열쇠 한 묶음을 찾고 있고, 그것을 찾기 위해 #Person2#...     열쇠 찾기  \n",
       "3  #Person1#은 #Person2#가 여자친구가 있고 그녀와 결혼할 것이라는 사실...  여자친구가 있다  \n",
       "4  말릭이 니키에게 춤을 요청한다. 말릭이 발을 밟는 것을 신경 쓰지 않는다면 니키는 ...        댄스  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config에 저장된 데이터 경로를 통해 train과 validation data를 불러옵니다.\n",
    "data_path = loaded_config['general']['data_path']\n",
    "\n",
    "# train data의 구조와 내용을 확인합니다.\n",
    "train_df = pd.read_csv(os.path.join(data_path,'/root/dialogue/data/samsum&train.csv'))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "FAGaYvNZ09Sq",
    "outputId": "bf8bf286-19e7-469d-ffae-41e6ad795ae6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13862856</td>\n",
       "      <td>Hannah needs Betty's number but Amanda doesn't...</td>\n",
       "      <td>Hannah: Hey, do you have Betty's number?\\nAman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13729565</td>\n",
       "      <td>Eric and Rob are going to watch a stand-up on ...</td>\n",
       "      <td>Eric: MACHINE!\\r\\nRob: That's so gr8!\\r\\nEric:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13680171</td>\n",
       "      <td>Lenny can't decide which trousers to buy. Bob ...</td>\n",
       "      <td>Lenny: Babe, can you help me with something?\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13729438</td>\n",
       "      <td>Emma will be home soon and she will let Will k...</td>\n",
       "      <td>Will: hey babe, what do you want for dinner to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13828600</td>\n",
       "      <td>Jane is in Warsaw. Ollie and Jane has a party....</td>\n",
       "      <td>Ollie: Hi , are you in Warsaw\\r\\nJane: yes, ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>13611902-1</td>\n",
       "      <td>Benjamin didn't come to see a basketball game ...</td>\n",
       "      <td>Alex: Were you able to attend Friday night's b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>13820989</td>\n",
       "      <td>The audition starts at 7.30 P.M. in Antena 3.</td>\n",
       "      <td>Jamilla: remember that the audition starts at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>13717193</td>\n",
       "      <td>Marta sent a file accidentally,</td>\n",
       "      <td>Marta: &lt;file_gif&gt;\\r\\nMarta: Sorry girls, I cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>13829115</td>\n",
       "      <td>There was a meet-and-greet with James Charles ...</td>\n",
       "      <td>Cora: Have you heard how much fuss British med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>13818810</td>\n",
       "      <td>Rachel sends a list of Top 50 films of 2018. J...</td>\n",
       "      <td>Rachel: &lt;file_other&gt;\\r\\nRachel: Top 50 Best Fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>819 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                            summary  \\\n",
       "0      13862856  Hannah needs Betty's number but Amanda doesn't...   \n",
       "1      13729565  Eric and Rob are going to watch a stand-up on ...   \n",
       "2      13680171  Lenny can't decide which trousers to buy. Bob ...   \n",
       "3      13729438  Emma will be home soon and she will let Will k...   \n",
       "4      13828600  Jane is in Warsaw. Ollie and Jane has a party....   \n",
       "..          ...                                                ...   \n",
       "814  13611902-1  Benjamin didn't come to see a basketball game ...   \n",
       "815    13820989      The audition starts at 7.30 P.M. in Antena 3.   \n",
       "816    13717193                    Marta sent a file accidentally,   \n",
       "817    13829115  There was a meet-and-greet with James Charles ...   \n",
       "818    13818810  Rachel sends a list of Top 50 films of 2018. J...   \n",
       "\n",
       "                                              dialogue  \n",
       "0    Hannah: Hey, do you have Betty's number?\\nAman...  \n",
       "1    Eric: MACHINE!\\r\\nRob: That's so gr8!\\r\\nEric:...  \n",
       "2    Lenny: Babe, can you help me with something?\\r...  \n",
       "3    Will: hey babe, what do you want for dinner to...  \n",
       "4    Ollie: Hi , are you in Warsaw\\r\\nJane: yes, ju...  \n",
       "..                                                 ...  \n",
       "814  Alex: Were you able to attend Friday night's b...  \n",
       "815  Jamilla: remember that the audition starts at ...  \n",
       "816  Marta: <file_gif>\\r\\nMarta: Sorry girls, I cli...  \n",
       "817  Cora: Have you heard how much fuss British med...  \n",
       "818  Rachel: <file_other>\\r\\nRachel: Top 50 Best Fi...  \n",
       "\n",
       "[819 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation data의 구조와 내용을 확인합니다.\n",
    "# val_df = pd.read_csv(os.path.join(data_path,'dev_translated.csv'))\n",
    "# val_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IIaIrpH4kWo"
   },
   "source": [
    "## 1. 데이터 가공 및 데이터셋 클래스 구축\n",
    "- csv file 을 불러와서 encoder 와 decoder의 입력형태로 가공해줍니다.\n",
    "- 가공된 데이터를 torch dataset class 로 구축하여 모델에 입력가능한 형태로 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "oWPawUUflwHa"
   },
   "outputs": [],
   "source": [
    "# # 데이터 전처리를 위한 클래스로, 데이터셋을 데이터프레임으로 변환하고 인코더와 디코더의 입력을 생성합니다.\n",
    "# class Preprocess:\n",
    "#     def __init__(self,\n",
    "#             bos_token: str,\n",
    "#             eos_token: str,\n",
    "#         ) -> None:\n",
    "\n",
    "#         self.bos_token = bos_token\n",
    "#         self.eos_token = eos_token\n",
    "      \n",
    "#     @staticmethod\n",
    "#     # 실험에 필요한 컬럼을 가져옵니다.\n",
    "#     def make_set_as_df(file_path, is_train = True):\n",
    "#         if is_train:\n",
    "#             df = pd.read_csv(file_path)\n",
    "#             train_df = df[['fname','dialogue','summary']]\n",
    "#             return train_df\n",
    "#         else:\n",
    "#             df = pd.read_csv(file_path)\n",
    "#             test_df = df[['fname','dialogue']]\n",
    "#             return test_df\n",
    "    \n",
    "    \n",
    "#     # BART 모델의 입력, 출력 형태를 맞추기 위해 전처리를 진행합니다.\n",
    "#     def make_input(self, dataset,is_test = False):\n",
    "\n",
    "#         if is_test:\n",
    "#             encoder_input = dataset['dialogue']\n",
    "#             decoder_input = [self.bos_token] * len(dataset['dialogue'])\n",
    "#             return encoder_input.tolist(), list(decoder_input)\n",
    "#         else:\n",
    "#             encoder_input = dataset['dialogue']\n",
    "#             decoder_input = dataset['summary'].apply(lambda x : self.bos_token + str(x)) # Ground truth를 디코더의 input으로 사용하여 학습합니다.\n",
    "#             decoder_output = dataset['summary'].apply(lambda x : str(x) + self.eos_token)\n",
    "#             return encoder_input.tolist(), decoder_input.tolist(), decoder_output.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# class Preprocess:\n",
    "#     def __init__(self,\n",
    "#             bos_token: str,\n",
    "#             eos_token: str,\n",
    "#         ) -> None:\n",
    "\n",
    "#         self.bos_token = bos_token\n",
    "#         self.eos_token = eos_token\n",
    "      \n",
    "#     @staticmethod\n",
    "#     # 실험에 필요한 컬럼을 가져옵니다.\n",
    "#     def make_set_as_df(file_path, is_train = True):\n",
    "#         if is_train:\n",
    "#             df = pd.read_csv(file_path)\n",
    "#             train_df = df[['fname','dialogue','summary']]\n",
    "#             return train_df\n",
    "#         else:\n",
    "#             df = pd.read_csv(file_path)\n",
    "#             test_df = df[['fname','dialogue']]\n",
    "#             return test_df\n",
    "    \n",
    "#     # 문장을 전처리하는 함수입니다.\n",
    "#     @staticmethod\n",
    "#     def preprocess_sentence(sentence: str) -> str:\n",
    "#         # sentence = sentence.lower()  # 텍스트 소문자화\n",
    "#         sentence = re.sub(r'[ㄱ-ㅎㅏ-ㅣ]+', '', sentence)  # 자음과 모음 제거\n",
    "#         sentence = re.sub(r'\\[.*?\\]', '', sentence)  # 대괄호로 둘러싸인 텍스트 제거\n",
    "#         sentence = re.sub(r\"([.,!?])\\1+\", r\"\\1\", sentence) \n",
    "#         sentence = re.sub(r\"[^가-힣a-z0-9#@,-\\[\\]\\(\\)]\", \" \", sentence)  # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "#         sentence = re.sub(r'[\" \"]+', \" \", sentence)  # 여러 개의 공백을 하나의 공백으로 바꿈\n",
    "#         sentence = sentence.strip()  # 문장 양쪽 공백 제거\n",
    "#         return sentence\n",
    "    \n",
    "#     # BART 모델의 입력, 출력 형태를 맞추기 위해 전처리를 진행합니다.\n",
    "#     def make_input(self, dataset, is_test = False):\n",
    "\n",
    "#         # 전처리 적용\n",
    "#         dataset['dialogue'] = dataset['dialogue'].apply(self.preprocess_sentence)\n",
    "#         if not is_test:\n",
    "#             dataset['summary'] = dataset['summary'].apply(self.preprocess_sentence)\n",
    "\n",
    "#         if is_test:\n",
    "#             encoder_input = dataset['dialogue']\n",
    "#             decoder_input = [self.bos_token] * len(dataset['dialogue'])\n",
    "#             return encoder_input.tolist(), list(decoder_input)\n",
    "#         else:\n",
    "#             encoder_input = dataset['dialogue']\n",
    "#             decoder_input = dataset['summary'].apply(lambda x : self.bos_token + str(x)) # Ground truth를 디코더의 input으로 사용하여 학습합니다.\n",
    "#             decoder_output = dataset['summary'].apply(lambda x : str(x) + self.eos_token)\n",
    "#             return encoder_input.tolist(), decoder_input.tolist(), decoder_output.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2729850141.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[75], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    samsum 학습용\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# samsum 학습용\n",
    "#  import pandas as pd\n",
    "# import re\n",
    "\n",
    "# class Preprocess:\n",
    "#     def __init__(self,\n",
    "#                  bos_token: str,\n",
    "#                  eos_token: str,\n",
    "#                  sep_token: str\n",
    "#                  ) -> None:\n",
    "\n",
    "#         self.bos_token = bos_token\n",
    "#         self.eos_token = eos_token\n",
    "#         self.sep_token = sep_token\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def make_set_as_df(file_path, is_train=True):\n",
    "#         if is_train:\n",
    "#             with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#                 data = json.load(file)\n",
    "#                 df = pd.DataFrame(data)\n",
    "#             # df = pd.read_csv(file_path)\n",
    "#             train_df = df[['id', 'dialogue', 'summary']]\n",
    "#             return train_df\n",
    "#         else:\n",
    "#             df = pd.read_csv(file_path)\n",
    "#             test_df = df[['fname', 'dialogue']]\n",
    "#             return test_df\n",
    "        \n",
    "#     def add_sep_tokens(self, dialogue):\n",
    "#         dialogue_with_sep = dialogue.replace('\\r\\n', f' {self.sep_token} ')\n",
    "#         return dialogue_with_sep\n",
    "\n",
    "#     def make_input(self, dataset, is_test=False):\n",
    "#         dataset['dialogue'] = dataset['dialogue'].apply(self.add_sep_tokens)\n",
    "\n",
    "#         if is_test:\n",
    "#             encoder_input = dataset['dialogue']\n",
    "#             decoder_input = [self.bos_token] * len(dataset['dialogue'])\n",
    "#             return encoder_input.tolist(), list(decoder_input)\n",
    "#         else:\n",
    "#             encoder_input = dataset['dialogue']\n",
    "#             decoder_input = dataset['summary'].apply(lambda x: self.bos_token + str(x)) \n",
    "#             decoder_output = dataset['summary'].apply(lambda x: str(x) + self.eos_token)\n",
    "        \n",
    "\n",
    "#             return encoder_input.tolist(), decoder_input.tolist(), decoder_output.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(self,\n",
    "                 bos_token: str,\n",
    "                 eos_token: str,\n",
    "                 sep_token: str\n",
    "                 ) -> None:\n",
    "\n",
    "        self.bos_token = bos_token\n",
    "        self.eos_token = eos_token\n",
    "        self.sep_token = sep_token\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_set_as_df(file_path, is_train=True):\n",
    "        if is_train:\n",
    "            df = pd.read_csv(file_path)\n",
    "            train_df = df[['fname', 'dialogue', 'summary']]\n",
    "            return train_df\n",
    "        else:\n",
    "            df = pd.read_csv(file_path)\n",
    "            test_df = df[['fname', 'dialogue']]\n",
    "            return test_df\n",
    "\n",
    "    def add_sep_tokens(self, dialogue_with_sep):\n",
    "        if isinstance(dialogue_with_sep, str):\n",
    "            dialogue_with_sep = re.sub(r'(\\r\\n|\\n)', f'{self.sep_token}', dialogue_with_sep)\n",
    "            return dialogue_with_sep\n",
    "        else:\n",
    "            return''\n",
    "\n",
    "    def make_input(self, dataset, is_test=False):\n",
    "        dataset['dialogue'] = dataset['dialogue'].apply(self.add_sep_tokens)\n",
    "\n",
    "        if is_test:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = [self.bos_token] * len(dataset['dialogue'])\n",
    "            return encoder_input.tolist(), list(decoder_input)\n",
    "        else:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = dataset['summary'].apply(lambda x: self.bos_token + str(x)) \n",
    "            decoder_output = dataset['summary'].apply(lambda x: str(x) + self.eos_token)\n",
    "        \n",
    "\n",
    "            return encoder_input.tolist(), decoder_input.tolist(), decoder_output.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# class Preprocess:\n",
    "#     def __init__(self, bos_token: str, eos_token: str, mask_token: str, sep_token: str) -> None:\n",
    "#         self.bos_token = bos_token\n",
    "#         self.eos_token = eos_token\n",
    "#         self.mask_token = mask_token\n",
    "#         self.sep_token = sep_token\n",
    "\n",
    "#     @staticmethod\n",
    "#     def make_set_as_df(file_path, is_train=True):\n",
    "#         if is_train:\n",
    "#             df = pd.read_csv(file_path)\n",
    "#             train_df = df[['fname', 'dialogue', 'summary']]\n",
    "#             return train_df\n",
    "#         else:\n",
    "#             df = pd.read_csv(file_path)\n",
    "#             test_df = df[['fname', 'dialogue']]\n",
    "#             return test_df\n",
    "\n",
    "#     def add_sep_tokens(self, dialogue):\n",
    "#         # 화자가 바뀔 때 SEP 토큰을 추가하는 함수\n",
    "#         pattern = r'(#Person\\d+#)'\n",
    "#         parts = re.split(pattern, dialogue)\n",
    "#         result = []\n",
    "#         prev_speaker = None\n",
    "#         for part in parts:\n",
    "#             if re.match(pattern, part):\n",
    "#                 if prev_speaker and prev_speaker != part:\n",
    "#                     result.append(self.sep_token)\n",
    "#                 prev_speaker = part\n",
    "#             result.append(part)\n",
    "#         return ''.join(result)\n",
    "    \n",
    "#     def apply_permute_or_infill(self, text, mask_token, mask_rate=0.15):\n",
    "#         # 발화자 태그 부분은 유지하고, 그 뒤의 텍스트만 처리\n",
    "#         def process_content(content, method):\n",
    "#             if method == \"permute\":\n",
    "#                 words = content.split()\n",
    "#                 return ' '.join(random.sample(words, len(words)))\n",
    "#             elif method == \"infill\":\n",
    "#                 tokens = content.split()\n",
    "#                 num_to_mask = int(len(tokens) * mask_rate)\n",
    "#                 masked_indices = random.sample(range(len(tokens)), num_to_mask)\n",
    "#                 for idx in masked_indices:\n",
    "#                     tokens[idx] = mask_token\n",
    "#                 return ' '.join(tokens)\n",
    "\n",
    "#         # 발화자 태그와 그 뒤의 내용으로 분리\n",
    "#         pattern = r'(#Person\\d+#:)'\n",
    "#         parts = re.split(pattern, text)\n",
    "#         processed_parts = []\n",
    "\n",
    "#         for i, part in enumerate(parts):\n",
    "#             if i % 2 == 0:  # 발화자 태그가 아닌 부분\n",
    "#                 if part.strip() == \"\":\n",
    "#                     continue\n",
    "#                 # 어떤 처리 방법을 사용할지 랜덤으로 선택\n",
    "#                 method = random.choice([\"permute\", \"infill\"])\n",
    "#                 processed_parts.append(process_content(part, method))\n",
    "#             else:  # 발화자 태그는 그대로 유지\n",
    "#                 processed_parts.append(part)\n",
    "                \n",
    "#         return ''.join(processed_parts)\n",
    "\n",
    "#     def make_input(self, dataset, is_test=False):\n",
    "#         dataset['original_dialogue'] = dataset['dialogue']\n",
    "#         dataset['original_dialogue'] = dataset['original_dialogue'].apply(self.add_sep_tokens)\n",
    "\n",
    "#         dataset['dialogue'] = dataset['dialogue'].apply(lambda x: self.apply_permute_or_infill(x, self.mask_token))\n",
    "#         dataset['dialogue'] = dataset['dialogue'].apply(self.add_sep_tokens)\n",
    "        \n",
    "#         if is_test:\n",
    "#             encoder_input = dataset['original_dialogue']\n",
    "#             decoder_input = [self.bos_token] * len(dataset['original_dialogue'])\n",
    "#             return encoder_input.tolist(), list(decoder_input)\n",
    "#         else:\n",
    "#             # 원본 대화\n",
    "#             original_encoder_input = dataset['original_dialogue']\n",
    "#             original_decoder_input = dataset['summary'].apply(lambda x: self.bos_token + str(x))\n",
    "#             original_decoder_output = dataset['summary'].apply(lambda x: str(x) + self.eos_token)\n",
    "\n",
    "#             # 순서가 섞인 대화 또는 infill이 적용된 대화\n",
    "#             processed_encoder_input = dataset['dialogue']\n",
    "#             processed_decoder_input = dataset['summary'].apply(lambda x: self.bos_token + str(x))\n",
    "#             processed_decoder_output = dataset['summary'].apply(lambda x: str(x) + self.eos_token)\n",
    "\n",
    "#             # 원본 데이터와 가공된 데이터 모두 포함\n",
    "#             encoder_input = original_encoder_input.tolist() + processed_encoder_input.tolist()\n",
    "#             decoder_input = original_decoder_input.tolist() + processed_decoder_input.tolist()\n",
    "#             decoder_output = original_decoder_output.tolist() + processed_decoder_output.tolist()\n",
    "\n",
    "#             return encoder_input, decoder_input, decoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "6GDvodoF8sED"
   },
   "outputs": [],
   "source": [
    "# Train에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForTrain(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()} # item2[input_ids], item2[attention_mask]\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        item.update(item2) #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item['labels'] = self.labels['input_ids'][idx] #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Validation에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForVal(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()} # item2[input_ids], item2[attention_mask]\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        item.update(item2) #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item['labels'] = self.labels['input_ids'][idx] #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Test에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForInference(Dataset):\n",
    "    def __init__(self, encoder_input, test_id, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.test_id = test_id\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n",
    "        item['ID'] = self.test_id[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "hT9z4vvS2CCb"
   },
   "outputs": [],
   "source": [
    "# tokenization 과정까지 진행된 최종적으로 모델에 입력될 데이터를 출력합니다.\n",
    "def prepare_train_dataset(config, preprocessor, data_path, tokenizer):\n",
    "    # train_file_path = os.path.join(data_path,'total_train.csv')\n",
    "    train_file_path = os.path.join('/root/dialogue/data/total_train.csv')\n",
    "    \n",
    "    # val_file_path = os.path.join(data_path,'dev.csv')\n",
    "    val_file_path = os.path.join('/root/dialogue/data/dev.csv')\n",
    "    \n",
    "\n",
    "    # train, validation에 대해 각각 데이터프레임을 구축합니다.\n",
    "    \n",
    "    train_data = preprocessor.make_set_as_df(train_file_path)\n",
    "    val_data = preprocessor.make_set_as_df(val_file_path)\n",
    "\n",
    "    # print('-'*150)\n",
    "    # print(f'train_data:\\n {train_data[\"translated_dialogue\"][0]}')\n",
    "    # print(f'train_label:\\n {train_data[\"translated_summary\"][0]}')\n",
    "\n",
    "    # print('-'*150)\n",
    "    # print(f'val_data:\\n {val_data[\"translated_dialogue\"][0]}')\n",
    "    # print(f'val_label:\\n {val_data[\"translated_summary\"][0]}')\n",
    "\n",
    "    encoder_input_train , decoder_input_train, decoder_output_train = preprocessor.make_input(train_data)\n",
    "    encoder_input_val , decoder_input_val, decoder_output_val = preprocessor.make_input(val_data)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "\n",
    "    tokenized_encoder_inputs = tokenizer(encoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                            add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_inputs = tokenizer(decoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_ouputs = tokenizer(decoder_output_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    train_inputs_dataset = DatasetForTrain(tokenized_encoder_inputs, tokenized_decoder_inputs, tokenized_decoder_ouputs,len(encoder_input_train))\n",
    "\n",
    "    val_tokenized_encoder_inputs = tokenizer(encoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_inputs = tokenizer(decoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_ouputs = tokenizer(decoder_output_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    val_inputs_dataset = DatasetForVal(val_tokenized_encoder_inputs, val_tokenized_decoder_inputs, val_tokenized_decoder_ouputs,len(encoder_input_val))\n",
    "\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "    return train_inputs_dataset, val_inputs_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5sKIJ5K5Pz1"
   },
   "source": [
    "## 2. Trainer 및 Trainingargs 구축하기\n",
    "- Huggingface 의 Trainer 와 Training arguments를 활용하여 모델 학습을 일괄적으로 처리해주는 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "aQk8ILcEeGNz"
   },
   "outputs": [],
   "source": [
    "# 모델 성능에 대한 평가 지표를 정의합니다. 본 대회에서는 ROUGE 점수를 통해 모델의 성능을 평가합니다.\n",
    "def compute_metrics(config,tokenizer,pred):\n",
    "    rouge = Rouge()\n",
    "    predictions = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, clean_up_tokenization_spaces=True)\n",
    "    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    # 정확한 평가를 위해 미리 정의된 불필요한 생성토큰들을 제거합니다.\n",
    "    replaced_predictions = decoded_preds.copy()\n",
    "    replaced_labels = labels.copy()\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    for token in remove_tokens:\n",
    "        replaced_predictions = [sentence.replace(token,\" \") for sentence in replaced_predictions]\n",
    "        replaced_labels = [sentence.replace(token,\" \") for sentence in replaced_labels]\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[0]}\")\n",
    "    print(f\"GOLD: {replaced_labels[0]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[1]}\")\n",
    "    print(f\"GOLD: {replaced_labels[1]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[2]}\")\n",
    "    print(f\"GOLD: {replaced_labels[2]}\")\n",
    "\n",
    "    # 최종적인 ROUGE 점수를 계산합니다.\n",
    "    results = rouge.get_scores(replaced_predictions, replaced_labels,avg=True)\n",
    "\n",
    "    # ROUGE 점수 중 F-1 score를 통해 평가합니다.\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "RInkG8g-HjBi"
   },
   "outputs": [],
   "source": [
    "# 학습을 위한 trainer 클래스와 매개변수를 정의합니다.\n",
    "def load_trainer_for_train(config,generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset):\n",
    "    print('-'*10, 'Make training arguments', '-'*10,)\n",
    "    # set training args\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "                output_dir=config['general']['output_dir'], # model output directory\n",
    "                overwrite_output_dir=config['training']['overwrite_output_dir'],\n",
    "                num_train_epochs=config['training']['num_train_epochs'],  # total number of training epochs\n",
    "                learning_rate=config['training']['learning_rate'], # learning_rate\n",
    "                per_device_train_batch_size=config['training']['per_device_train_batch_size'], # batch size per device during training\n",
    "                per_device_eval_batch_size=config['training']['per_device_eval_batch_size'],# batch size for evaluation\n",
    "                warmup_ratio=config['training']['warmup_ratio'],  # number of warmup steps for learning rate scheduler\n",
    "                weight_decay=config['training']['weight_decay'],  # strength of weight decay\n",
    "                lr_scheduler_type=config['training']['lr_scheduler_type'],\n",
    "                optim =config['training']['optim'],\n",
    "                gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],\n",
    "                evaluation_strategy=config['training']['evaluation_strategy'], # evaluation strategy to adopt during training\n",
    "                save_strategy =config['training']['save_strategy'],\n",
    "                save_total_limit=config['training']['save_total_limit'], # number of total save model.\n",
    "                fp16=config['training']['fp16'],\n",
    "                load_best_model_at_end=config['training']['load_best_model_at_end'], # 최종적으로 가장 높은 점수 저장\n",
    "                seed=config['training']['seed'],\n",
    "                logging_dir=config['training']['logging_dir'], # directory for storing logs\n",
    "                logging_strategy=config['training']['logging_strategy'],\n",
    "                predict_with_generate=config['training']['predict_with_generate'], #To use BLEU or ROUGE score\n",
    "                generation_max_length=config['training']['generation_max_length'],\n",
    "                do_train=config['training']['do_train'],\n",
    "                do_eval=config['training']['do_eval'],\n",
    "                report_to=config['training']['report_to'] # (선택) wandb를 사용할 때 설정합니다.\n",
    "            )\n",
    "\n",
    "    # (선택) 모델의 학습 과정을 추적하는 wandb를 사용하기 위해 초기화 해줍니다.\n",
    "    wandb.init(\n",
    "        # entity=config['wandb']['entity'],\n",
    "        project=config['wandb']['project'],\n",
    "        name=config['wandb']['name'],\n",
    "    )\n",
    "\n",
    "    # # (선택) 모델 checkpoint를 wandb에 저장하도록 환경 변수를 설정합니다.\n",
    "    os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "    os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "\n",
    "    # Validation loss가 더 이상 개선되지 않을 때 학습을 중단시키는 EarlyStopping 기능을 사용합니다.\n",
    "    MyCallback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=config['training']['early_stopping_patience'],\n",
    "        early_stopping_threshold=config['training']['early_stopping_threshold']\n",
    "    )\n",
    "    print('-'*10, 'Make training arguments complete', '-'*10,)\n",
    "    print('-'*10, 'Make trainer', '-'*10,)\n",
    "\n",
    "    # Trainer 클래스를 정의합니다.\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=generate_model, # 사용자가 사전 학습하기 위해 사용할 모델을 입력합니다.\n",
    "        args=training_args,\n",
    "        train_dataset=train_inputs_dataset,\n",
    "        eval_dataset=val_inputs_dataset,\n",
    "        compute_metrics = lambda pred: compute_metrics(config,tokenizer, pred),\n",
    "        callbacks = [MyCallback]\n",
    "    )\n",
    "    print('-'*10, 'Make trainer complete', '-'*10,)\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "KKWHe8dE5fSx"
   },
   "outputs": [],
   "source": [
    "# # 학습을 위한 tokenizer와 사전 학습된 모델을 불러옵니다.\n",
    "# def load_tokenizer_and_model_for_train(config,device):\n",
    "#     print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "#     print('-'*10, f'Model Name : {config[\"general\"][\"model_name\"]}', '-'*10,)\n",
    "#     model_name = config['general']['model_name']\n",
    "#     bart_config = BartConfig().from_pretrained(model_name)\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#     generate_model = BartForConditionalGeneration.from_pretrained(config['general']['model_name'], config=bart_config)\n",
    "\n",
    "#     special_tokens_dict={'additional_special_tokens':config['tokenizer']['special_tokens']}\n",
    "#     tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "#     generate_model.resize_token_embeddings(len(tokenizer)) # 사전에 special token을 추가했으므로 재구성 해줍니다.\n",
    "#     generate_model.to(device)\n",
    "#     print(generate_model.config)\n",
    "\n",
    "#     print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "\n",
    "\n",
    "#     # data_collator = DataCollatorForSeq2Seq(\n",
    "#     #     tokenizer=tokenizer,\n",
    "#     #     model = generate_model\n",
    "#     # )\n",
    "#     return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_tokenizer_and_model_for_train(config, device):\n",
    "#     print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "#     print('-'*10, f'Model Name : {config[\"general\"][\"model_name\"]}', '-'*10,)\n",
    "#     model_name = config['general']['model_name']\n",
    "#     model_config = T5Config.from_pretrained(model_name)\n",
    "    \n",
    "#     tokenizer = T5TokenizerFast.from_pretrained(model_name)\n",
    "#     special_tokens_dict={'additional_special_tokens':config['tokenizer']['special_tokens']}\n",
    "#     tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    \n",
    "#     generate_model = T5ForConditionalGeneration.from_pretrained(config['general']['model_name'], config=model_config)\n",
    "#     generate_model.resize_token_embeddings(len(tokenizer)) # 사전에 special token을 추가했으므로 재구성 해줍니다.\n",
    "#     generate_model.to(device)\n",
    "#     print(generate_model.config)\n",
    "\n",
    "#     print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "#     return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: ['▁Amanda', '▁baked', '▁cookies', '▁and', '▁will', '▁bring', '▁Jerry', '▁some', '.']\n",
      "Decoded: Amanda baked cookies and will bring Jerry some.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "\n",
    "df = pd.read_csv(\"/root/dialouge/data/translate/train_total.csv\")\n",
    "df1 = pd.read_csv(\"/root/dialouge/data/translate/test_translated.csv\")\n",
    "df2 = pd.read_csv('/root/dialouge/data/translate/dev_translated.csv')\n",
    "corpus = df['translated_dialogue'].tolist() + df['translated_summary'].tolist() +df1['translated_dialogue'].tolist()+df2['translated_dialogue'].tolist() + df2['translated_summary'].tolist()\n",
    "\n",
    "# Save corpus to a text file\n",
    "with open('corpus.txt', 'w', encoding='utf-8') as f:\n",
    "    for line in corpus:\n",
    "        f.write(str(line) + '\\n')\n",
    "\n",
    "# Train SentencePiece model\n",
    "spm.SentencePieceTrainer.Train('--input=corpus.txt --model_prefix=spm --vocab_size=32000 --model_type=bpe')\n",
    "\n",
    "sp = spm.SentencePieceProcessor(model_file='spm.model')\n",
    "\n",
    "# Test the model\n",
    "test_sentence = \"Amanda baked cookies and will bring Jerry some.\"\n",
    "encoded = sp.encode(test_sentence, out_type=str)\n",
    "decoded = sp.decode(encoded)\n",
    "\n",
    "print(\"Encoded:\", encoded)\n",
    "print(\"Decoded:\", decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_tokenizer_and_model_for_train(config, device):\n",
    "#     print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "#     print('-'*10, f'Model Name : {config[\"general\"][\"model_name\"]}', '-'*10,)\n",
    "#     model_name = config['general']['model_name']\n",
    "\n",
    "    \n",
    "#     bart_config = BartConfig().from_pretrained(model_name)\n",
    "#     tokenizer = spm.SentencePieceProcessor(model_file='spm.model')\n",
    "#     # tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "#     generate_model = BartForConditionalGeneration.from_pretrained(config['general']['model_name'], config=bart_config)\n",
    "\n",
    "#     special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}\n",
    "#     tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "#     generate_model.resize_token_embeddings(len(tokenizer))  # 사전에 special token을 추가했으므로 재구성 해줍니다.\n",
    "#     generate_model.to(device)\n",
    "#     print(generate_model.config)\n",
    "\n",
    "#     print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "\n",
    "#     return generate_model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer_and_model_for_train(config, device):\n",
    "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "    print('-'*10, f'Model Name : {config[\"general\"][\"model_name\"]}', '-'*10,)\n",
    "    model_name = config['general']['model_name']\n",
    "\n",
    "    \n",
    "    bart_config = BartConfig().from_pretrained(model_name)\n",
    "    # tokenizer = spm.SentencePieceProcessor(model_file='spm.model')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    generate_model = BartForConditionalGeneration.from_pretrained(config['general']['model_name'], config=bart_config)\n",
    "\n",
    "    special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model.resize_token_embeddings(len(tokenizer))  # 사전에 special token을 추가했으므로 재구성 해줍니다.\n",
    "    generate_model.to(device)\n",
    "    print(generate_model.config)\n",
    "\n",
    "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "\n",
    "    return generate_model, tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvutzKQYvQgl"
   },
   "source": [
    "## 3. 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(config):\n",
    "#     # 사용할 device를 정의합니다.\n",
    "#     device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#     print('-'*10, f'device : {device}', '-'*10,)\n",
    "#     print(torch.__version__)\n",
    "\n",
    "#     # 사용할 모델과 tokenizer를 불러옵니다.\n",
    "#     generate_model, tokenizer= load_tokenizer_and_model_for_train(config, device)\n",
    "#     print('-'*10, \"tokenizer special tokens : \", tokenizer.special_tokens_map, '-'*10)\n",
    "\n",
    "#     # 학습에 사용할 데이터셋을 불러옵니다.\n",
    "#     preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])\n",
    "#     data_path = config['general']['data_path']\n",
    "#     train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(config, preprocessor, data_path, tokenizer)\n",
    "\n",
    "#     # Trainer 클래스를 불러옵니다.\n",
    "#     trainer = load_trainer_for_train(config, generate_model, tokenizer, train_inputs_dataset, val_inputs_dataset)\n",
    "#     trainer.train()  # 모델 학습을 시작합니다.\n",
    "\n",
    "#     # (선택) 모델 학습이 완료된 후 wandb를 종료합니다.\n",
    "#     wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImZUb-BC42J-"
   },
   "source": [
    "- 앞에서 구축한 클래스 및 함수를 활용하여 학습 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "qnA96wmR44is"
   },
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    # 사용할 device를 정의합니다.\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print('-'*10, f'device : {device}', '-'*10,)\n",
    "    print(torch.__version__)\n",
    "\n",
    "    # 사용할 모델과 tokenizer를 불러옵니다.\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_train(config,device)\n",
    "    # print('-'*10,\"tokenizer special tokens : \",tokenizer.special_tokens_map,'-'*10)\n",
    "\n",
    "    # 학습에 사용할 데이터셋을 불러옵니다.\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'], config['tokenizer']['sep_token']) # decoder_start_token: str, eos_token: str\n",
    "    data_path = config['general']['data_path']\n",
    "    train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(config,preprocessor, data_path, tokenizer)\n",
    "\n",
    "    # Trainer 클래스를 불러옵니다.\n",
    "    trainer = load_trainer_for_train(config, generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset)\n",
    "    trainer.train()   # 모델 학습을 시작합니다.\n",
    "\n",
    "    # (선택) 모델 학습이 완료된 후 wandb를 종료합니다.\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1DMS60wL-Dhv",
    "outputId": "cbb6aba7-18ff-4d12-b9e7-2a2ef31d94d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.1.0\n",
      "---------- Load tokenizer & model ----------\n",
      "---------- Model Name : EbanLee/kobart-summary-v3 ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a22d348e5174aa79aef8ae72cf22860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.68k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc14e3f12aaa4496a572bf91cee24480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e23d64bf9b42069c9c1590ca7d4f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BartConfig {\n",
      "  \"_name_or_path\": \"EbanLee/kobart-summary-v3\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"author\": \"EbanLee(rudwo6769@gmail.com)\",\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"kobart_version\": 2.0,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 300,\n",
      "      \"min_length\": 12,\n",
      "      \"no_repeat_ngram_size\": 15,\n",
      "      \"num_beams\": 6,\n",
      "      \"repetition_penalty\": 1.5\n",
      "    }\n",
      "  },\n",
      "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30011\n",
      "}\n",
      "\n",
      "---------- Load tokenizer & model complete ----------\n",
      "---------- Load data complete ----------\n",
      "---------- Make dataset complete ----------\n",
      "---------- Make training arguments ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjosuhan1433\u001b[0m (\u001b[33msuhan_up\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/dialogue/baseline/wandb/run-20240908_130636-ph86soa9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/suhan_up/summary/runs/ph86soa9' target=\"_blank\">bartv3</a></strong> to <a href='https://wandb.ai/suhan_up/summary' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/suhan_up/summary' target=\"_blank\">https://wandb.ai/suhan_up/summary</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/suhan_up/summary/runs/ph86soa9' target=\"_blank\">https://wandb.ai/suhan_up/summary/runs/ph86soa9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make training arguments complete ----------\n",
      "---------- Make trainer ----------\n",
      "---------- Make trainer complete ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7501' max='17310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7501/17310 53:39 < 1:10:11, 2.33 it/s, Epoch 13/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.866900</td>\n",
       "      <td>0.639214</td>\n",
       "      <td>0.328429</td>\n",
       "      <td>0.104352</td>\n",
       "      <td>0.312359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.621200</td>\n",
       "      <td>0.589484</td>\n",
       "      <td>0.357580</td>\n",
       "      <td>0.123799</td>\n",
       "      <td>0.341672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>0.560398</td>\n",
       "      <td>0.366149</td>\n",
       "      <td>0.129279</td>\n",
       "      <td>0.345534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.536500</td>\n",
       "      <td>0.543899</td>\n",
       "      <td>0.375323</td>\n",
       "      <td>0.135360</td>\n",
       "      <td>0.357153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.506900</td>\n",
       "      <td>0.535035</td>\n",
       "      <td>0.376557</td>\n",
       "      <td>0.137205</td>\n",
       "      <td>0.357020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.483100</td>\n",
       "      <td>0.529704</td>\n",
       "      <td>0.371931</td>\n",
       "      <td>0.137560</td>\n",
       "      <td>0.355705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.461900</td>\n",
       "      <td>0.525603</td>\n",
       "      <td>0.375567</td>\n",
       "      <td>0.141111</td>\n",
       "      <td>0.358251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.443900</td>\n",
       "      <td>0.523452</td>\n",
       "      <td>0.374802</td>\n",
       "      <td>0.139705</td>\n",
       "      <td>0.357182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.426900</td>\n",
       "      <td>0.521803</td>\n",
       "      <td>0.375875</td>\n",
       "      <td>0.145028</td>\n",
       "      <td>0.361030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>0.521661</td>\n",
       "      <td>0.379832</td>\n",
       "      <td>0.142472</td>\n",
       "      <td>0.361088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.397300</td>\n",
       "      <td>0.523526</td>\n",
       "      <td>0.381359</td>\n",
       "      <td>0.147924</td>\n",
       "      <td>0.364775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.383900</td>\n",
       "      <td>0.526493</td>\n",
       "      <td>0.382191</td>\n",
       "      <td>0.148448</td>\n",
       "      <td>0.365718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.372100</td>\n",
       "      <td>0.525857</td>\n",
       "      <td>0.381153</td>\n",
       "      <td>0.149362</td>\n",
       "      <td>0.365288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1# 은 #Person2# 에게 감기에 걸렸다고 말하고, #Person2# 는 #Person1# 에게 폐 전문의에게 천식에 대한 검사를 받게 할 것이라고 말합니다.                                                                                                                                                                      \n",
      "GOLD:  #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                               \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:    지미는 헤이의 운동에 대해 #Person1# 에게 말하고, #Person1# 은 #Person1# 에게 금요일에 다리를 할 수 있다고 말합니다.                                                                                                                                                                          \n",
      "GOLD:  #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1# 은 #Person2# 에게 과일, 채소, 닭고기를 먹는 것을 멈추라고 말합니다. #Person2# 는 닭고기를 구워 먹는 것이 건강에 좋다고 말합니다.                                                                                                                                                                     \n",
      "GOLD:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1# 은 #Person2# 에게 감기에 걸렸다고 말하고, #Person2# 는 #Person1# 에게 폐 전문의에게 천식에 대한 검사를 받게 할 것이라고 말합니다.                                                                \n",
      "GOLD:  #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                               \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:    지미는 지미의 주간 스케줄을 따라 운동하러 갈 것이다. 지미는 금요일에 다리를 할 수 있다.                                                                            \n",
      "GOLD:  #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1# 은 #Person2# 에게 과일, 채소, 닭고기를 먹는 것을 멈추라고 제안한다. #Person2# 는 닭고기를 구워 먹는 것을 추천한다.                                                                 \n",
      "GOLD:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1# 은 #Person2# 에게 감기에 걸렸다고 말하고, #Person2# 는 #Person1# 에게 폐 전문의에게 가서 천식에 대한 검사를 받게 할 것이라고 말합니다.                                             \n",
      "GOLD:  #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                               \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:    지미는 지미가 금요일에 다리를 할 수 있도록 3시 30분에 헬스장에서 운동하러 가자고 제안한다.                                                        \n",
      "GOLD:  #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1# 은 #Person2# 에게 건강한 음식을 먹는 것을 멈춰야 한다고 말하고, #Person2# 는 과일, 채소, 닭고기를 먹는 것을 좋아한다고 말한다.                                               \n",
      "GOLD:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person2# 는 감기에 걸렸지만, #Person1# 는 천식에 걸리지 않았다. #Person2# 는 #Person1# 을 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이다.                                                      \n",
      "GOLD:  #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                               \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:    지미는 지미에게 운동하러 가자고 제안한다. 지미는 동의하고 금요일에 다리를 할 수 있다고 말한다.                                                                 \n",
      "GOLD:  #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1# 은 #Person2# 에게 더 이상 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말하고, #Person2# 는 주로 과일, 채소, 그리고 닭고기를 먹는다고 말한다.                                                     \n",
      "GOLD:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person2# 는 감기에 걸리지 않았지만, 운동을 할 때 많이 나타난다. #Person1# 는 #Person2# 를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이다.                                                              \n",
      "GOLD:  #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                               \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:    지미는 #Person1# 에게 운동하자고 제안하고 #Person1# 은 동의한다. 그들은 3시 30분에 헬스장에서 만나기로 한다.                                                                      \n",
      "GOLD:  #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1# 은 #Person2# 에게 #Person2# 가 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말합니다. #Person2# 는 닭고기를 먹는 것을 선호합니다.                                                                 \n",
      "GOLD:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person2# 는 감기에 걸리지 않았지만, 운동을 할 때 많이 나타난다. #Person1# 은 #Person2# 를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이다.                                                            \n",
      "GOLD:  #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                               \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:    지미는 #Person1# 에게 운동하자고 제안하고, #Person1# 은 지미의 주간 스케줄을 따르고 있다고 말한다.                                                                      \n",
      "GOLD:  #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1# 은 #Person2# 에게 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말하고, #Person2# 는 주로 과일, 채소, 그리고 닭고기를 먹는다고 말한다.                                                            \n",
      "GOLD:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person2# 는 감기에 걸리지 않았지만, 운동을 할 때 많이 나타난다. #Person1# 는 #Person2# 를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이다.                                                     \n",
      "GOLD:  #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                               \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:    지미는 지미와 함께 운동하러 가자고 제안한다. 그들은 3시 30분에 헬스장에서 만날 것이다.                                                                  \n",
      "GOLD:  #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1# 은 #Person2# 에게 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말하고, #Person2# 는 주로 과일, 채소, 그리고 닭고기를 먹는다고 말한다.                                                     \n",
      "GOLD:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person2# 는 감기에 걸리지 않았지만, 운동을 할 때 많이 나타난다. #Person1# 은 #Person2# 를 천식에 대한 검사를 받게 할 것이다.                                                                     \n",
      "GOLD:  #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                               \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:    지미는 #Person1# 에게 운동하자고 제안한다. #Person1# 은 주간 스케줄을 따르고 있기 때문에 지미가 금요일에 다리를 할 수 있다고 말한다.                                                                  \n",
      "GOLD:  #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1# 은 #Person2# 에게 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말한다. #Person2# 는 주로 과일, 채소, 그리고 닭고기를 먹는다.                                                                 \n",
      "GOLD:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person2# 는 감기에 걸리지 않았지만, 운동을 할 때 많이 나타난다. #Person1# 는 #Person2# 를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이다.                                                              \n",
      "GOLD:  #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                               \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:    지미와 #Person1# 은 3시 30분에 헬스장에서 만나서 운동하기로 결정한다.                                                                              \n",
      "GOLD:  #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1# 은 #Person2# 에게 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말합니다. #Person2# 는 과일, 채소, 그리고 닭고기를 먹는 것을 선호합니다.                                                               \n",
      "GOLD:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person2# 는 숨쉬기가 힘들다고 #Person1# 에게 말합니다. #Person1# 는 #Person2# 를 폐 전문의에게 보내 천식에 대한 검사를 받게 할 것입니다.                                                              \n",
      "GOLD:  #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                               \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:    지미는 #Person1# 에게 운동하자고 제안한다. #Person1# 은 주간 스케줄을 따르고 있기 때문에 동의하지 않는다. 그들은 3시 30분에 헬스장에서 만날 것이다.                                                            \n",
      "GOLD:  #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1# 은 #Person2# 에게 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말합니다. #Person2# 는 주로 과일, 채소, 그리고 닭고기를 먹는 편입니다.                                                             \n",
      "GOLD:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person2# 는 숨쉬기가 힘들다고 #Person1# 에게 말합니다. #Person1# 은 #Person2# 를 폐 전문의에게 보내 천식에 대한 검사를 받게 할 것입니다.                                                                          \n",
      "GOLD:  #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                               \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:    지미와 #Person1# 은 3시 30분에 헬스장에서 운동하기로 결정했다.                                                                                          \n",
      "GOLD:  #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1# 은 #Person2# 에게 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말합니다. #Person2# 는 주로 과일, 채소, 그리고 닭고기를 먹는다고 말합니다.                                                                        \n",
      "GOLD:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person2# 는 숨쉬기가 힘들다고 #Person1# 에게 말합니다. #Person1# 는 #Person2# 를 폐 전문의에게 보내 천식에 대한 검사를 받게 할 것입니다.                                                                  \n",
      "GOLD:  #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                               \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:    지미와 #Person1# 은 3시 30분에 운동하러 가기로 결정했다.                                                                                   \n",
      "GOLD:  #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1# 은 #Person2# 에게 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말합니다. #Person2# 는 주로 과일, 채소, 그리고 닭고기를 먹는 편입니다.                                                                 \n",
      "GOLD:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person2# 는 숨쉬기가 힘들다고 #Person1# 에게 말합니다. #Person1# 는 #Person2# 를 폐 전문의에게 보내 천식에 대한 검사를 받게 할 것입니다.                                                          \n",
      "GOLD:  #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                               \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:    지미와 #Person1# 은 3시 30분에 헬스장에서 운동하기로 결정했다.                                                                          \n",
      "GOLD:  #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1# 은 #Person2# 에게 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말합니다. #Person2# 는 주로 과일, 채소, 그리고 닭고기를 먹는 편입니다.                                                         \n",
      "GOLD:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b62ddb2608455d9b931f0d88371565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='472.677 MB of 472.677 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/rouge-1</td><td>▁▅▆▇▇▇▇▇▇████</td></tr><tr><td>eval/rouge-2</td><td>▁▄▅▆▆▆▇▆▇▇███</td></tr><tr><td>eval/rouge-l</td><td>▁▅▅▇▇▇▇▇▇▇███</td></tr><tr><td>eval/runtime</td><td>█▁▁▁▁▁▁▂▁▁▁▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▁██████▇▇██▇█</td></tr><tr><td>eval/steps_per_second</td><td>▁██████▇▇██▇█</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▁▅████▇▇▇▆▆▅▅</td></tr><tr><td>train/loss</td><td>█▅▄▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.52586</td></tr><tr><td>eval/rouge-1</td><td>0.38115</td></tr><tr><td>eval/rouge-2</td><td>0.14936</td></tr><tr><td>eval/rouge-l</td><td>0.36529</td></tr><tr><td>eval/runtime</td><td>9.6233</td></tr><tr><td>eval/samples_per_second</td><td>51.854</td></tr><tr><td>eval/steps_per_second</td><td>1.663</td></tr><tr><td>train/epoch</td><td>13.0</td></tr><tr><td>train/global_step</td><td>7501</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.3721</td></tr><tr><td>train/total_flos</td><td>1.1156807660544e+17</td></tr><tr><td>train/train_loss</td><td>0.49884</td></tr><tr><td>train/train_runtime</td><td>3217.5445</td></tr><tr><td>train/train_samples_per_second</td><td>268.77</td></tr><tr><td>train/train_steps_per_second</td><td>5.38</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bartv3</strong> at: <a href='https://wandb.ai/suhan_up/summary/runs/ph86soa9' target=\"_blank\">https://wandb.ai/suhan_up/summary/runs/ph86soa9</a><br/>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240908_130636-ph86soa9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(loaded_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFtWqowCGzEc"
   },
   "source": [
    "## 4. 모델 추론하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이곳에 내가 사용할 wandb config 설정\n",
    "loaded_config['inference']['ckt_path'] = \"/root/dialogue/baseline/checkpoint-7501\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFGul3-rSscf"
   },
   "source": [
    "- test data를 사용하여 모델의 성능을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "lV1Do7nlTylG"
   },
   "outputs": [],
   "source": [
    "# tokenization 과정까지 진행된 최종적으로 모델에 입력될 데이터를 출력합니다.\n",
    "def prepare_test_dataset(config,preprocessor, tokenizer):\n",
    "\n",
    "    # test_file_path = os.path.join(config['general']['data_path'],'test.csv')\n",
    "    test_file_path = os.path.join('/root/dialogue/data/test.csv')\n",
    "\n",
    "    test_data = preprocessor.make_set_as_df(test_file_path,is_train=False)\n",
    "    test_id = test_data['fname']\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'test_data:\\n{test_data[\"dialogue\"][0]}')\n",
    "    print('-'*150)\n",
    "\n",
    "    encoder_input_test , decoder_input_test = preprocessor.make_input(test_data,is_test=True)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "\n",
    "    test_tokenized_encoder_inputs = tokenizer(encoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False,)\n",
    "    test_tokenized_decoder_inputs = tokenizer(decoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False,)\n",
    "\n",
    "    test_encoder_inputs_dataset = DatasetForInference(test_tokenized_encoder_inputs, test_id, len(encoder_input_test))\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "\n",
    "    return test_data, test_encoder_inputs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "eb49bLULT3aS"
   },
   "outputs": [],
   "source": [
    "# 추론을 위한 tokenizer와 학습시킨 모델을 불러옵니다.\n",
    "def load_tokenizer_and_model_for_test(config,device):\n",
    "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "\n",
    "    model_name = config['general']['model_name']\n",
    "    ckt_path = config['inference']['ckt_path']\n",
    "    print('-'*10, f'Model Name : {model_name}', '-'*10,)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model = BartForConditionalGeneration.from_pretrained(ckt_path)\n",
    "    generate_model.resize_token_embeddings(len(tokenizer))\n",
    "    generate_model.to(device)\n",
    "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "Axzu9rsoGLgJ"
   },
   "outputs": [],
   "source": [
    "# 학습된 모델이 생성한 요약문의 출력 결과를 보여줍니다.\n",
    "def inference(config):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print('-'*10, f'device : {device}', '-'*10,)\n",
    "    print(torch.__version__)\n",
    "\n",
    "    generate_model , tokenizer= load_tokenizer_and_model_for_test(config,device)\n",
    "\n",
    "    data_path = config['general']['data_path']\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'],config['tokenizer']['sep_token'])\n",
    "\n",
    "    test_data, test_encoder_inputs_dataset = prepare_test_dataset(config,preprocessor, tokenizer)\n",
    "    dataloader = DataLoader(test_encoder_inputs_dataset, batch_size=config['inference']['batch_size'])\n",
    "\n",
    "    summary = []\n",
    "    text_ids = []\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(dataloader):\n",
    "            text_ids.extend(item['ID'])\n",
    "            generated_ids = generate_model.generate(input_ids=item['input_ids'].to('cuda:0'),\n",
    "                            no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
    "                            early_stopping=config['inference']['early_stopping'],\n",
    "                            max_length=config['inference']['generate_max_length'],\n",
    "                            num_beams=config['inference']['num_beams'],\n",
    "                        )\n",
    "            for ids in generated_ids:\n",
    "                result = tokenizer.decode(ids)\n",
    "                summary.append(result)\n",
    "\n",
    "    # 정확한 평가를 위하여 노이즈에 해당되는 스페셜 토큰을 제거합니다.\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    preprocessed_summary = summary.copy()\n",
    "    for token in remove_tokens:\n",
    "        preprocessed_summary = [sentence.replace(token,\" \") for sentence in preprocessed_summary]\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"fname\": test_data['fname'],\n",
    "            \"summary\" : preprocessed_summary,\n",
    "        }\n",
    "    )\n",
    "    result_path = config['inference']['result_path']\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    output.to_csv(os.path.join(result_path, \"output.csv\"), index=False)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "-pJ1ZXf-5V50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.1.0\n",
      "---------- Load tokenizer & model ----------\n",
      "---------- Model Name : EbanLee/kobart-summary-v3 ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Load tokenizer & model complete ----------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "test_data:\n",
      "#Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \n",
      "#Person2#: 네, 실장님...\n",
      "#Person1#: 이것은 오늘 오후까지 모든 직원에게 내부 메모로 전달되어야 합니다. 준비되셨나요?\n",
      "#Person2#: 네, 실장님. 시작하셔도 됩니다.\n",
      "#Person1#: 모든 직원들에게 주의하라... 즉시 효력을 발휘하여, 모든 사무실 통신은 이메일 통신과 공식 메모로 제한됩니다. 근무 시간 동안 직원들이 즉시 메시지 프로그램을 사용하는 것은 엄격히 금지됩니다.\n",
      "#Person2#: 실장님, 이것은 내부 통신에만 적용되는 건가요? 아니면 외부 통신에도 제한이 되는 건가요?\n",
      "#Person1#: 이것은 모든 통신에 적용되어야 합니다, 이 사무실 내의 직원들 사이뿐만 아니라 외부 통신에도 마찬가지입니다.\n",
      "#Person2#: 하지만 실장님, 많은 직원들이 고객과 소통하기 위해 즉시 메시지를 사용하고 있습니다.\n",
      "#Person1#: 그들은 그들의 의사소통 방법을 바꾸어야만 합니다. 이 사무실에서 누구도 즉시 메시지를 사용하지 않기를 원합니다. 너무 많은 시간을 낭비하게 됩니다! 이제, 메모를 계속해주세요. 우리가 어디까지 했나요?\n",
      "#Person2#: 이것은 내부와 외부 통신에 적용됩니다.\n",
      "#Person1#: 그렇습니다. 즉시 메시지를 계속 사용하는 어떤 직원이라도 먼저 경고를 받고 직무 정지에 처해질 것입니다. 두 번째 위반 시에는 직원은 해고에 처해질 것입니다. 이 새로운 정책에 대한 어떤 질문이라도 부서장에게 직접 문의하면 됩니다.\n",
      "#Person2#: 그게 다신가요?\n",
      "#Person1#: 네. 이 메모를 오후 4시 전에 모든 직원에게 타이핑하여 배포해 주세요.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "---------- Load data complete ----------\n",
      "---------- Make dataset complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:23<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델의 test를 진행합니다.\n",
    "if __name__ == \"__main__\":\n",
    "    output = inference(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "OsPmLfhbzZqS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         더슨 씨는 실장에게 모든 직원에게 내부 메모가 전달되어야 하며, 모든 직원들이...\n",
       "1        #Person2# 는 교통 체증에 걸렸다. #Person1# 는 #Person2...\n",
       "2         케이트는 마샤와 히어로가 2개월 동안 별거 중이다가 이혼을 신청했다고 #Per...\n",
       "3        #Person1# 은 브라이언의 생일을 축하하기 위해 파티를 열어준다. 그들은 ...\n",
       "4        #Person2# 는 #Person1# 에게 올림픽 스타디움에 5000개의 좌석...\n",
       "                             ...                        \n",
       "494       찰리가 잭에게 새 비디오 게임에 초대하고 잭은 흥미롭다고 생각한다.      ...\n",
       "495      #Person2# 는 #Person1# 에게 컨트리 음악에 관심을 가지게 된 계...\n",
       "496       앨리스는 세탁기를 사용해본 적이 없습니다. #Person1# 은 그에게 기계가...\n",
       "497       스티브는 매튜에게 그녀의 계약이 다음 달에 끝나기 때문에 집을 찾고 있다고 말...\n",
       "498       프랭크가 벳시에게 승진하고 친구들 모두를 위한 큰 파티를 열 계획이라고 말한다...\n",
       "Name: summary, Length: 499, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['summary']  # 각 대화문에 대한 요약문이 출력됨을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "083ea69907bb48d4a8fff919bac51aad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08d05bc20a96432badd459e1ffaf868e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13651c09564a4337b8274c1cb436faa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14f6c91d6c634379b498586c51e606e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21d2e54b5a0a4f79973a512105da43eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2307c6dcbe0141acb5e61baae19cade7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "285007b45236478ca147c6df752c8da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a190bda0b72407e9a953cd2104dd3b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fd3d7bbcd6948d8904d33001f95ea03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3645438ace1f4596a8dbc157b48c1521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14f6c91d6c634379b498586c51e606e0",
      "placeholder": "​",
      "style": "IPY_MODEL_08d05bc20a96432badd459e1ffaf868e",
      "value": " 295/295 [00:00&lt;00:00, 21.3kB/s]"
     }
    },
    "3a04e871b74b45d7bf02fd33bb103577": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3bcd6b6b956347b29e1efa20a1d00542": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c284a826f6843f6aa47eacad478ac30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_affff1d8a89e4c14955d1b2aa39ff1ab",
      "placeholder": "​",
      "style": "IPY_MODEL_13651c09564a4337b8274c1cb436faa5",
      "value": "tokenizer.json: 100%"
     }
    },
    "45187decb58b4ad39ad532259c6277e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4747b668e2fa4ab58a449446f80030f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52095cc7087243ac916055e569fd22f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c18f0e3bc35e44d9915c3f84cd282a26",
      "max": 109,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a04e871b74b45d7bf02fd33bb103577",
      "value": 109
     }
    },
    "58001a60eacc44d5b38a68648adccde4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58c794fb7ce543a39fdf66d757f6eeab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f5fde5b0ac840a18bd5cc380e564ff6",
      "placeholder": "​",
      "style": "IPY_MODEL_45187decb58b4ad39ad532259c6277e5",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "5dfcf310ca9e4e2794076098a5d69cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c284a826f6843f6aa47eacad478ac30",
       "IPY_MODEL_6caedd60c6b747469c82930be1f95d6d",
       "IPY_MODEL_64f2218f899d446393cfea44f206f0a6"
      ],
      "layout": "IPY_MODEL_d068f541df3f438dbd5138863e64b2f2"
     }
    },
    "64f2218f899d446393cfea44f206f0a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d22fbc2c5dbf422399e496c9b500025a",
      "placeholder": "​",
      "style": "IPY_MODEL_775d8bbeceac4e2da4f21ab6235c89ed",
      "value": " 682k/682k [00:00&lt;00:00, 5.40MB/s]"
     }
    },
    "6caedd60c6b747469c82930be1f95d6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bcd6b6b956347b29e1efa20a1d00542",
      "max": 682133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fd3d7bbcd6948d8904d33001f95ea03",
      "value": 682133
     }
    },
    "6f5fde5b0ac840a18bd5cc380e564ff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "775d8bbeceac4e2da4f21ab6235c89ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a6464a355f7464c989033965d418a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2307c6dcbe0141acb5e61baae19cade7",
      "max": 295,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4747b668e2fa4ab58a449446f80030f5",
      "value": 295
     }
    },
    "a15af9e8158f4903b9189f3d322a5ef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac00d6c2cf974b33a628acb3f1471316",
      "placeholder": "​",
      "style": "IPY_MODEL_285007b45236478ca147c6df752c8da4",
      "value": " 109/109 [00:00&lt;00:00, 9.44kB/s]"
     }
    },
    "ac00d6c2cf974b33a628acb3f1471316": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "affff1d8a89e4c14955d1b2aa39ff1ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18f0e3bc35e44d9915c3f84cd282a26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d068f541df3f438dbd5138863e64b2f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d22fbc2c5dbf422399e496c9b500025a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de1a3f7701c243839fe03b930a9b9e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebc22683058a4f229c5588e52fc93536",
       "IPY_MODEL_52095cc7087243ac916055e569fd22f3",
       "IPY_MODEL_a15af9e8158f4903b9189f3d322a5ef3"
      ],
      "layout": "IPY_MODEL_21d2e54b5a0a4f79973a512105da43eb"
     }
    },
    "e920dbc173c045d1a32143349f1dff8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58c794fb7ce543a39fdf66d757f6eeab",
       "IPY_MODEL_8a6464a355f7464c989033965d418a8a",
       "IPY_MODEL_3645438ace1f4596a8dbc157b48c1521"
      ],
      "layout": "IPY_MODEL_58001a60eacc44d5b38a68648adccde4"
     }
    },
    "ebc22683058a4f229c5588e52fc93536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_083ea69907bb48d4a8fff919bac51aad",
      "placeholder": "​",
      "style": "IPY_MODEL_2a190bda0b72407e9a953cd2104dd3b2",
      "value": "special_tokens_map.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
