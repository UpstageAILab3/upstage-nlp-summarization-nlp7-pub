{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/root/dialouge/data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "data_path = '/root/dialouge/data/'\n",
    "train = pd.read_csv(os.path.join(data_path,'train.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약문과 대화 길이 \n",
    "\n",
    "* max_length 조절을 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대화 길이에 대한 정보\n",
      "count    28826.000000\n",
      "mean       351.743565\n",
      "std        307.942919\n",
      "min          3.000000\n",
      "25%        173.000000\n",
      "50%        316.000000\n",
      "75%        468.000000\n",
      "max      33043.000000\n",
      "Name: dialogue, dtype: float64\n",
      "=================\n",
      "요약문 길이에 대한 정보\n",
      "count    28826.000000\n",
      "mean        73.608236\n",
      "std         37.897022\n",
      "min          3.000000\n",
      "25%         46.000000\n",
      "50%         67.000000\n",
      "75%         94.000000\n",
      "max        478.000000\n",
      "Name: summary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# dialog 와 summary 각각의 모델 max_length 설정을 위한 길이 확인\n",
    "import pandas as pd\n",
    "import json\n",
    "df = pd.read_csv('/root/dialogue/data/total_train.csv')\n",
    "\n",
    "\n",
    "train_dialog_length = df['dialogue'].apply(lambda x: len(str(x)))\n",
    "train_summary_length = df['summary'].apply(lambda x: len(str(x)))\n",
    "\n",
    "print(\"대화 길이에 대한 정보\")\n",
    "print(train_dialog_length.describe())\n",
    "print(\"=================\")\n",
    "print(\"요약문 길이에 대한 정보\")\n",
    "print(train_summary_length.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자주 사용하는 단어 확인\n",
    "\n",
    "* TF-IDF(Term Frequency - Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 토큰화 결과 ==> ['#Person1', '#:', '안녕하세요', ',', '스미스', '씨', '.', '저', '는', '호킨스', '의사', '입니다', '.', '오늘', '왜', '오셨나요', '?', '\\n', '#Person2', '#:', '건강검진', '을', '받는', '것', '이', '좋을', '것', '같아서요', '.', '\\n', '#Person1', '#:', '그렇군요', ',', '당신', '은', '5년', '동안', '건강검진', '을', '받지', '않았습니다', '.', '매년', '받아야', '합니다', '.', '\\n', '#Person2', '#:', '알', '고', '있습니다', '.', '하지만', '아무', '문제', '가', '없다면', '왜', '의사', '를', '만나러', '가야', '하나요', '?', '\\n', '#Person1', '#:', '심각한', '질병', '을', '피하', '는', '가장', '좋은', '방법', '은', '이를', '조기', '에', '발견', '하는', '것', '입니다', '.', '그러니', '당신', '의', '건강', '을', '위해', '최소한', '매년', '한', '번은', '오세요', '.', '\\n', '#Person2', '#:', '알겠습니다', '.', '\\n', '#Person1', '#:', '여기', '보세요', '.', '당신', '의', '눈', '과', '귀', '는', '괜찮아', '보입니다', '.', '깊게', '숨', '을', '들이', '쉬세요', '.', '스미스', '씨', ',', '담배', '피우시나요', '?', '\\n', '#Person2', '#:', '네', '.', '\\n', '#Person1', '#:', '당신', '도', '알다시피', ',', '담배', '는', '폐암', '과', '심장병', '의', '주요', '원인', '입니다', '.', '정말로', '끊으셔야', '합니다', '.', '#Person2', '#:', '수백', '번', '시도', '했지만', ',', '습관', '을', '버리는', '것', '이', '어렵습니다', '.', '\\n', '#Person1', '#:', '우리', '는', '도움', '이', '될', '수', '있는', '수업', '과', '약물', '들', '을', '제공', '하고', '있습니다', '.', '나가기', '전', '에', '더', '많은', '정보', '를', '드리겠습니다', '.', '\\n', '#Person2', '#:', '알겠습니다', ',', '감사합니다', ',', '의사', '선생님', '.']\n"
     ]
    }
   ],
   "source": [
    "# 단어 토큰화, 명사 추출 \n",
    "from konlpy.tag import Okt\n",
    "k=Okt()\n",
    "\n",
    "print('단어 토큰화 결과 ==>', k.morphs(train['dialogue'].iloc[0]))\n",
    "# print('명사 추출 결과 ==>', k.nouns(train['dialogue'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 개인정보 마스킹 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 마스킹 정보 확인\n",
    "'''\n",
    "전화번호 → #PhoneNumber#\n",
    "주소 → #Address#\n",
    "생년월일 → #DateOfBirth#\n",
    "여권번호 → #PassportNumber#\n",
    "사회보장번호 → #SSN#\n",
    "신용카드 번호 → #CardNumber#\n",
    "차량 번호 → #CarNumber#\n",
    "이메일 주소 → #Email#\n",
    "'''\n",
    "# 정규표현식 사용하기 \n",
    "import re\n",
    "\n",
    "\n",
    "df = pd.read_csv('/root/dialouge/output1.csv')\n",
    "def reg_masking(text):\n",
    "  pattern = r\"#\\w+#\"  # ## 사이의 값을 추출하는 정규식 패턴\n",
    "  masked = re.findall(pattern, text)\n",
    "  return masked\n",
    "\n",
    "train_set = df['dialogue'].apply(lambda x:str(set(reg_masking(x))))\n",
    "train_set.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.발화자 확인\n",
    "import re\n",
    "def reg_person(text):\n",
    "  pattern = r\"#\\w+\\d#\"  # ## 사이의 값을 추출하는 정규식 패턴 > special token 으로 tokenizer에 추가\n",
    "  masked = re.findall(pattern, text)\n",
    "  return masked\n",
    "\n",
    "train_person = train['dialogue'].apply(lambda x:set(reg_person(x)))\n",
    "train_person\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None 'Person2' 'Person1']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('/root/dialouge/output2.csv')\n",
    "\n",
    "# 특정 컬럼에서 #과 # 사이의 값을 추출하는 함수 정의\n",
    "def extract_between_hashes(text):\n",
    "    if pd.isna(text):  # NaN 값 체크\n",
    "        return None\n",
    "    matches = re.findall(r'#(.*?)#', text)\n",
    "    return matches[0] if matches else None  # 첫 번째 매치된 값 반환, 없으면 None\n",
    "\n",
    "# 'summary' 컬럼에 대해 #과 # 사이의 값을 추출\n",
    "if 'summary' in df.columns:  # 'summary' 컬럼이 있는지 확인\n",
    "    df['summary'] = df['summary'].apply(extract_between_hashes)\n",
    "    # 결과 출력\n",
    "    print(df['summary'].unique())\n",
    "else:\n",
    "    print(\"'summary' 컬럼이 존재하지 않습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['#Email#',\n",
       "  '#DateOfBirth#',\n",
       "  '#CarNumber#',\n",
       "  '#PassportNumber#',\n",
       "  '#Person2#',\n",
       "  '#Address#',\n",
       "  '#Person1#',\n",
       "  '#CardNumber#',\n",
       "  '#Person3#',\n",
       "  '#PhoneNumber#',\n",
       "  '#SSN#'],\n",
       " [30000, 30001, 30002, 30003, 30004, 30005, 30006, 30007, 30008, 30009, 30010])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. special token 추가\n",
    "# train_11716 -> ##person#으로 되어 있음\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "unique_token = [\n",
    "    \"#PhoneNumber#\", \"#Address#\", \"#DateOfBirth#\", \n",
    "    \"#PassportNumber#\", \"#SSN#\", \"#CardNumber#\", \n",
    "    \"#CarNumber#\", \"#Email#\",\"#Person1#\", \"#Person2#\", \"#Person3#\"\n",
    "]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gogamza/kobart-base-v2\")\n",
    "special_tokens_dict = {'additional_special_tokens': unique_token}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "tokenizer.additional_special_tokens, tokenizer.additional_special_tokens_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AEDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mecab-python3\n",
      "  Obtaining dependency information for mecab-python3 from https://files.pythonhosted.org/packages/9b/7e/29dd338e62dfbfaa0b656442d2a31a6d822c048a247dabae5a22608ae88a/mecab_python3-1.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading mecab_python3-1.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Downloading mecab_python3-1.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (581 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.7/581.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: mecab-python3\n",
      "Successfully installed mecab-python3-1.0.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install mecab-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "mecab = MeCab.Tagger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'파커 부인이 리키를 데리고 백신 접종을 하러 갔다. 피터스 박사는 기록을 확인한 후 리키에게 백신을 접종했다.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =train['summary'][:4]\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from koeda import EasyDataAugmentation\n",
    "\n",
    "def augment_text_data_with_EDA(text,repetition):\n",
    "    \"\"\"입력된 문장에 대해서 EDA를 통해 데이터 증강\"\"\"\n",
    "    eda = EasyDataAugmentation(\n",
    "        morpheme_analyzer=\"Okt\"\n",
    "        )\n",
    "\n",
    "    result = eda(text,p=(0.5, 0.5, 0.5, 0.5), repetition=repetition)\n",
    "\n",
    "    # 증강 결과 출력\n",
    "    print(\"원문: \" , text)\n",
    "    print(\"--\"*100)\n",
    "    for i in range(repetition):\n",
    "        print(f\"증강문{i+1}: \", result[i])\n",
    "    # return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Updating TextAttack package dependencies.\n",
      "textattack: Downloading NLTK required packages.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /data/ephemeral/home/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /data/ephemeral/home/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package omw to\n",
      "[nltk_data]     /data/ephemeral/home/nltk_data...\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /data/ephemeral/home/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /data/ephemeral/home/nltk_data...\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /data/ephemeral/home/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /data/ephemeral/home/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dialogue:\n",
      " #Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요? #Person2#: 건강검진을 받는 것이 좋을 것 같아서요. #Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다. #Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요? #Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요. #Person2#: 알겠습니다. #Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요? #Person2#: 네. #Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. #Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다. #Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다. #Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
      "Augmented Dialogue:\n",
      " ['#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요? #Person2#: 건강검진을 받는 것이 좋을 것 같아서요. #Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다. #Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요? #Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요. #Person2#: 알겠습니다. #Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요? #Person2#: 네. #Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. #Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다. #Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다. #Person2#: 알겠습니다, 감사합니다, 의사선생님.', '#Person1#: 안녕하세요, 스미스씨. 매년 호킨스 의사입니다. 오늘 왜 오셨나요? #Person2#: 건강검진을 받는 것이 좋을 것 같아서요. #심장병의#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다. #Person2#: 알고 있습니다. 담배는 보입니다 문제가 없다면 왜 의사를 만나러 가야 하나요? #Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 저는 한 번은 오세요. #Person2#: 알겠습니다. #Person1#: 여기 보세요. 당신의 어렵습니다 귀는 괜찮아 아무. 깊게 원인입니다 들이쉬세요. 스미스씨, 담배 피우시나요? #Person2#: 네. #Person1#: 당신도 알다시피, 하지만 폐암과 Person1 주요 숨을. 정말로 끊으셔야 합니다. #Person2#: 수백 번 시도했지만, 습관을 버리는 것이 눈과. #Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다. #Person2#: 알겠습니다, 감사합니다, 의사선생님.', '#Person1#: 안녕하세요, 스미스씨. 호킨스 의사입니다. 오늘 왜 오셨나요? #Person2#: 건강검진을 받는 것이 좋을 같아서요. #Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다. #Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요? #Person1#: 심각한 질병을 피하는 좋은 방법은 조기에 발견하는 것입니다. 그러니 건강을 위해 매년 한 번은 오세요. #Person2#: 알겠습니다. #Person1#:. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요? #Person2#: 네. #Person1#: 당신도 알다시피, 담배는 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. #Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다. #Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 있습니다. 나가기 더 많은 정보를 드리겠습니다. #Person2#: 알겠습니다, 감사합니다, 의사선생님.']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from textattack.augmentation import EasyDataAugmenter\n",
    "import pandas as pd\n",
    "\n",
    "# AEDA 증강기를 초기화합니다.\n",
    "eda_augmenter = EasyDataAugmenter()\n",
    "\n",
    "# 대화문을 증강하는 함수입니다.\n",
    "def augment_dialogue(dialogue: str, augmenter) -> str:\n",
    "    return augmenter.augment(dialogue)\n",
    "\n",
    "# 원본 대화문 데이터\n",
    "data = [\n",
    "    {\n",
    "        \"fname\": \"train_0\",\n",
    "        \"dialogue\": \"#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요? #Person2#: 건강검진을 받는 것이 좋을 것 같아서요. #Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다. #Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요? #Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요. #Person2#: 알겠습니다. #Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요? #Person2#: 네. #Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. #Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다. #Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다. #Person2#: 알겠습니다, 감사합니다, 의사선생님.\",\n",
    "        \"summary\": \"스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니다. 호킨스 의사는 스미스씨가 담배를 끊는 데 도움이 될 수 있는 수업과 약물에 대한 정보를 제공할 것입니다.\",\n",
    "        \"topic\": \"건강검진 받기\"\n",
    "    },\n",
    "    # 다른 데이터 샘플...\n",
    "]\n",
    "\n",
    "# 대화문 증강 예제\n",
    "for entry in data:\n",
    "    original_dialogue = entry[\"dialogue\"]\n",
    "    augmented_dialogue = augment_dialogue(original_dialogue, eda_augmenter)\n",
    "    \n",
    "    print(\"Original Dialogue:\\n\", original_dialogue)\n",
    "    print(\"Augmented Dialogue:\\n\", augmented_dialogue)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/5e/4d/affea11bd85ca69d9fdd15567495bb9088ac1c37498c95cb42d9ecd984ed/openai-1.43.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.43.0-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/56/95/9377bcb415797e44274b51d46e3249eba641711cf3348050f76ee7b15ffc/httpx-0.27.2-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Obtaining dependency information for jiter<1,>=0.4.0 from https://files.pythonhosted.org/packages/41/6a/c038077509d67fe876c724bfe9ad15334593851a7def0d84518172bdd44a/jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Obtaining dependency information for pydantic<3,>=1.9.0 from https://files.pythonhosted.org/packages/1f/fa/b7f815b8c9ad021c07f88875b601222ef5e70619391ade4a49234d12d278/pydantic-2.8.2-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.5)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Obtaining dependency information for typing-extensions<5,>=4.11 from https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.0.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/78/d4/e5d7e4f2174f8a4d63c8897d79eb8fe2503f7ecc03282fee1fa2719c2704/httpcore-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for h11<0.15,>=0.13 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic<3,>=1.9.0->openai)\n",
      "  Obtaining dependency information for pydantic-core==2.20.1 from https://files.pythonhosted.org/packages/ae/49/8a6fe79d35e2f3bea566d8ea0e4e6f436d4f749d7838c8e8c4c5148ae706/pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Downloading openai-1.43.0-py3-none-any.whl (365 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing-extensions, jiter, h11, distro, annotated-types, pydantic-core, httpcore, pydantic, httpx, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "Successfully installed annotated-types-0.7.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.43.0 pydantic-2.8.2 pydantic-core-2.20.1 typing-extensions-4.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation completed and saved to output_.csv.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI  # Ensure this version is installed: openai==1.2.0\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=\"api\",  # Replace with your actual API key\n",
    "    base_url=\"https://api.upstage.ai/v1/solar\"\n",
    ")\n",
    "\n",
    "# Function to translate text using the solar-1-mini-translate-enko model\n",
    "def translate_text(text,summary, translate_summary):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"solar-1-mini-translate-enko\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": translate_summary\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": summary\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": text\n",
    "                }\n",
    "            ],\n",
    "            stream=False  # Set to True if you want to use streaming\n",
    "        )\n",
    "        # Return the translated text\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating text: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/root/dialouge/code/prediction/output.csv\") \n",
    "df_train = pd.read_csv('/root/dialouge/data/translate/train_translated.csv')\n",
    "\n",
    "# Translate each summary\n",
    "df[\"translated_summary\"] = df[\"translated_summary\",\"summary\",\"text\"].apply(translate_text)\n",
    "\n",
    "df.to_csv(\"output_.csv\", index=False)\n",
    "print(\"saved to output_.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to output_.csv.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI  # Ensure this version is installed: openai==1.2.0\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=\"up_CNqmlQHjivsljcVtjTtfMJlfoT7jE\",  # Replace with your actual API key\n",
    "    base_url=\"https://api.upstage.ai/v1/solar\"\n",
    ")\n",
    "\n",
    "# Function to translate text using the solar-1-mini-translate-enko model\n",
    "def translate_text(text):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"solar-1-mini-translate-enko\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"#Person2#'s mom lost her job. #Person2# doesn't want her mom to be depressed. #Person1# suggests #Person2# look for job leads on the internet.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"#Person2#의 엄마가 일자리를 잃었다. #Person2#는 엄마가 우울해하지 않기를 바란다. #Person1#은 #Person2#에게 인터넷에서 일자리 정보를 찾아보는 것을 제안한다.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"#Person1# asks #Person2# for advice on how to pack a bag for a visit to this uncle's house next Saturday.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"#Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 #Person2#에게 조언을 구합니다.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"데이브는 #Person2#가 그가 웹트래커에서 일하고 있다는 것을 추론할 수 있다는 사실에 놀란다.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"Dave is surprised that #Person2# can deduce that he is working for WebTracker.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Bill tells #Person1# that he found out his roommate is Brain Locker.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"빌은 #Person1#에게 자신의 룸메이트가 브래인 로커라는 것을 알게 되었다고 말한다.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": text\n",
    "                }\n",
    "            ],\n",
    "            stream=False  # Set to True if you want to use streaming\n",
    "        )\n",
    "        # Return the translated text\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating text: {e}\")\n",
    "        return None\n",
    "\n",
    "df = pd.read_csv(\"/root/dialouge/code/prediction/output.csv\") \n",
    "\n",
    "# Translate each summary\n",
    "df[\"translated_summary\"] = df[\"summary\"].apply(translate_text)\n",
    "\n",
    "df.to_csv(\"output_.csv\", index=False)\n",
    "print(\"saved to output_.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/root/dialouge/output_.csv')\n",
    "\n",
    "df = df.drop(columns='summary', axis=0)\n",
    "\n",
    "df = df.rename(columns={\"translated_summary\":\"summary\"})\n",
    "\n",
    "df.to_csv('output2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/root/dialogue/baseline/prediction/output.csv')\n",
    "df.summary = df.summary.str.strip()\n",
    "df.to_csv('output3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13818513</td>\n",
       "      <td>Amanda baked cookies and will bring Jerry some...</td>\n",
       "      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13728867</td>\n",
       "      <td>Olivia and Olivier are voting for liberals in ...</td>\n",
       "      <td>Olivia: Who are you voting for in this electio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13681000</td>\n",
       "      <td>Kim may try the pomodoro technique recommended...</td>\n",
       "      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13730747</td>\n",
       "      <td>Edward thinks he is in love with Bella. Rachel...</td>\n",
       "      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13728094</td>\n",
       "      <td>Sam is confused, because he overheard Rick com...</td>\n",
       "      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15545</th>\n",
       "      <td>13829423</td>\n",
       "      <td>Carla's date for graduation is on June 4th. Di...</td>\n",
       "      <td>Carla: I've got it...\\r\\nDiego: what?\\r\\nCarla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15546</th>\n",
       "      <td>13727710</td>\n",
       "      <td>Bev is going on the school trip with her son. ...</td>\n",
       "      <td>Gita: Hello, this is Beti's Mum Gita, I wanted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15547</th>\n",
       "      <td>13829261</td>\n",
       "      <td>Greg cheated on Julia. He apologises to her. R...</td>\n",
       "      <td>Julia: Greg just texted me\\r\\nRobert: ugh, del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15548</th>\n",
       "      <td>13680226</td>\n",
       "      <td>Marry broke her nail and has a party tomorrow....</td>\n",
       "      <td>Marry: I broke my nail ;(\\r\\nTina: oh, no!\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15549</th>\n",
       "      <td>13862383</td>\n",
       "      <td>Paige wants to have the declaration sent later...</td>\n",
       "      <td>Paige: I asked them to wait and send the decla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15550 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                            summary  \\\n",
       "0      13818513  Amanda baked cookies and will bring Jerry some...   \n",
       "1      13728867  Olivia and Olivier are voting for liberals in ...   \n",
       "2      13681000  Kim may try the pomodoro technique recommended...   \n",
       "3      13730747  Edward thinks he is in love with Bella. Rachel...   \n",
       "4      13728094  Sam is confused, because he overheard Rick com...   \n",
       "...         ...                                                ...   \n",
       "15545  13829423  Carla's date for graduation is on June 4th. Di...   \n",
       "15546  13727710  Bev is going on the school trip with her son. ...   \n",
       "15547  13829261  Greg cheated on Julia. He apologises to her. R...   \n",
       "15548  13680226  Marry broke her nail and has a party tomorrow....   \n",
       "15549  13862383  Paige wants to have the declaration sent later...   \n",
       "\n",
       "                                                dialogue  \n",
       "0      Amanda: I baked  cookies. Do you want some?\\r\\...  \n",
       "1      Olivia: Who are you voting for in this electio...  \n",
       "2      Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...  \n",
       "3      Edward: Rachel, I think I'm in ove with Bella....  \n",
       "4      Sam: hey  overheard rick say something\\r\\nSam:...  \n",
       "...                                                  ...  \n",
       "15545  Carla: I've got it...\\r\\nDiego: what?\\r\\nCarla...  \n",
       "15546  Gita: Hello, this is Beti's Mum Gita, I wanted...  \n",
       "15547  Julia: Greg just texted me\\r\\nRobert: ugh, del...  \n",
       "15548  Marry: I broke my nail ;(\\r\\nTina: oh, no!\\r\\n...  \n",
       "15549  Paige: I asked them to wait and send the decla...  \n",
       "\n",
       "[15550 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "with open('/root/dialouge/data/train.json', 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>translated_summary</th>\n",
       "      <th>translated_dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13818513</td>\n",
       "      <td>Amanda baked cookies and will bring Jerry some...</td>\n",
       "      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13728867</td>\n",
       "      <td>Olivia and Olivier are voting for liberals in ...</td>\n",
       "      <td>Olivia: Who are you voting for in this electio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13681000</td>\n",
       "      <td>Kim may try the pomodoro technique recommended...</td>\n",
       "      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13730747</td>\n",
       "      <td>Edward thinks he is in love with Bella. Rachel...</td>\n",
       "      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13728094</td>\n",
       "      <td>Sam is confused, because he overheard Rick com...</td>\n",
       "      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15545</th>\n",
       "      <td>13829423</td>\n",
       "      <td>Carla's date for graduation is on June 4th. Di...</td>\n",
       "      <td>Carla: I've got it...\\r\\nDiego: what?\\r\\nCarla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15546</th>\n",
       "      <td>13727710</td>\n",
       "      <td>Bev is going on the school trip with her son. ...</td>\n",
       "      <td>Gita: Hello, this is Beti's Mum Gita, I wanted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15547</th>\n",
       "      <td>13829261</td>\n",
       "      <td>Greg cheated on Julia. He apologises to her. R...</td>\n",
       "      <td>Julia: Greg just texted me\\r\\nRobert: ugh, del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15548</th>\n",
       "      <td>13680226</td>\n",
       "      <td>Marry broke her nail and has a party tomorrow....</td>\n",
       "      <td>Marry: I broke my nail ;(\\r\\nTina: oh, no!\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15549</th>\n",
       "      <td>13862383</td>\n",
       "      <td>Paige wants to have the declaration sent later...</td>\n",
       "      <td>Paige: I asked them to wait and send the decla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15550 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                 translated_summary  \\\n",
       "0      13818513  Amanda baked cookies and will bring Jerry some...   \n",
       "1      13728867  Olivia and Olivier are voting for liberals in ...   \n",
       "2      13681000  Kim may try the pomodoro technique recommended...   \n",
       "3      13730747  Edward thinks he is in love with Bella. Rachel...   \n",
       "4      13728094  Sam is confused, because he overheard Rick com...   \n",
       "...         ...                                                ...   \n",
       "15545  13829423  Carla's date for graduation is on June 4th. Di...   \n",
       "15546  13727710  Bev is going on the school trip with her son. ...   \n",
       "15547  13829261  Greg cheated on Julia. He apologises to her. R...   \n",
       "15548  13680226  Marry broke her nail and has a party tomorrow....   \n",
       "15549  13862383  Paige wants to have the declaration sent later...   \n",
       "\n",
       "                                     translated_dialogue  \n",
       "0      Amanda: I baked  cookies. Do you want some?\\r\\...  \n",
       "1      Olivia: Who are you voting for in this electio...  \n",
       "2      Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...  \n",
       "3      Edward: Rachel, I think I'm in ove with Bella....  \n",
       "4      Sam: hey  overheard rick say something\\r\\nSam:...  \n",
       "...                                                  ...  \n",
       "15545  Carla: I've got it...\\r\\nDiego: what?\\r\\nCarla...  \n",
       "15546  Gita: Hello, this is Beti's Mum Gita, I wanted...  \n",
       "15547  Julia: Greg just texted me\\r\\nRobert: ugh, del...  \n",
       "15548  Marry: I broke my nail ;(\\r\\nTina: oh, no!\\r\\n...  \n",
       "15549  Paige: I asked them to wait and send the decla...  \n",
       "\n",
       "[15550 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns = {'summary':'translated_summary', 'dialogue':'translated_dialogue'})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/root/dialouge/data/translate/train_translated.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_fname = df1['fname'].iloc[-1]  # 'train_0'\n",
    "last_index = int(last_fname.split('_')[1])\n",
    "next_index = last_index + 1\n",
    "\n",
    "# Create new entries for df1\n",
    "df_new = pd.DataFrame({\n",
    "    'fname': [f'train_{i}' for i in range(next_index, next_index + len(df))],\n",
    "    'dialogue': df['translated_dialogue'].tolist(),\n",
    "    'summary': df['translated_summary'].tolist(),\n",
    "    'topic': [''] * len(df),  # Adjust as needed\n",
    "    'translated_dialogue': df['translated_dialogue'].tolist(),\n",
    "    'translated_summary': df['translated_summary'].tolist()\n",
    "})\n",
    "\n",
    "# Append df_new to df1\n",
    "df1_updated = pd.concat([df1, df_new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
